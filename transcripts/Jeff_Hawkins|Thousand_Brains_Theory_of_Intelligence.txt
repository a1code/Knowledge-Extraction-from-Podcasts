The following is a conversation with Jeff Hawkins. he is the founder of the Redwoods Center for Theoretical Neuroscience in 2002 and Numenta in 2005, in his 2004 book titled Unintelligence. And in the research before and after, he and his team have worked to reverse engineer the neocortex and propose artificial intelligence architectures, approaches and ideas that are inspired by the human brain. These ideas include hierarchical Tupper Memory, ASTM from 2004 and New Work The Thousands Brain Theory of Intelligence from 2017 18 and 19.
Jeff's ideas have been an inspiration to many who have looked for progress beyond the current machine learning approaches. But they have also received criticism for lacking a body of empirical evidence supporting the models. This is always a challenge when seeking more than small, incremental steps forward. And I, Jeff, is a brilliant mind and many of the ideas he has developed and aggregated from neuroscience are worth understanding and thinking about. There are limits to deep learning as it is currently defined forward progress and AI is shrouded in mystery.
My hope is that conversations like this can help provide an inspiring spark for new ideas. This is the Artificial Intelligence podcast if you enjoy it. Subscribe on YouTube, iTunes or simply connect with me on Twitter. Ã€lex Friedman spelled Frid. And now here is my conversation with Jeff Hawkins. Are you more interested in understanding the human brain or in creating artificial systems that have many of the same qualities but do not necessarily require that you actually understand the underpinning workings of our mind?
So there is a clear answer to that question. My primary interest is understanding the human brain.
No question about it, but. I also firmly believe that we will not be able to create fully intelligent machines until we understand how the human brain works, so I do not see those as separate problems. I think there is limits to what can be done with machine intelligence if you do not understand the principles by which the brain works. And so I actually believe that studying the brain is actually the the fastest way to get the machine intelligence.
And within that. Let me ask the impossible question. How do you not define but at least think about what it means to be intelligent?
So I did not try to answer that question. First we said let us just talk about how the brain works and let us figure out how different parts of the brain, mostly the neocortex, but some other parts to the parts of the brain most associated with intelligence. And let us discover other principles by how they work, because intelligence is not just like some mechanism, and it is not just some capabilities.
it is like, OK, we do not even know where to begin on this stuff and.
So now that we have made a lot of progress on this after we have made a lot of progress on how the neocortex works and we can talk about that, I now have a very good idea what is going to be required to make intelligent machines. I can tell you today some of the things are going to be necessary, I believe, to create intelligent machines.
So we will get there. we will get to the neocortex and some of the theories of how the whole thing works. And you are saying, as we understand more and more about the neocortex, about our own human mind, we will be able to start to more specifically define what it means to be intelligence. Not useful to really talk about that until I do not know if it is not useful.
Look, there is a long history of A.I., as you know, and there is been different approaches taken to it. And who knows, maybe they are all useful. Right. All right. So, you know, the good old fashioned A.I., the expert systems, current convolutional neural networks, they all have their utility. They all have a value in the world. But I would think almost everyone agree that none of them are really intelligent and a sort of a deep way that that humans are.
And so it is it is just the question of how do you get from where those systems were or are today to where a lot of people think we are going to go? Right. And there is a big, big gap there, a huge gap. And I think the quickest way of bridging that gap is to figure out how the brain does that. And then we can sit back and look and say, oh, what do these principles that the brain works on are necessary and which ones are not?
We do not have to build this in and told the machines are not going to be built out of, you know, organic living cells. But there is a lot of stuff that goes on. The brain is going to be necessary.
So let me ask maybe before we get into the fun details, let me ask maybe a depressing or difficult question. Do you think it is possible that we will never be able to understand how our brain works, that maybe there is aspects to the human mind, like we ourselves cannot introspectively get to the core that there is a wall you eventually hit?
Yeah, I do not believe that is the case. I have never believe that is the case, there is not even a single thing we have ever. Humans have ever put their minds to that. We said, oh, we reached the wall. We can not go any further. It just people keep saying that people used to believe that about life, you know. Alan Vittal. Right. there is like, what is the difference in living matter? In non-living matter? Something special you never understand.
We no longer think that. So there is there is no historical evidence to suggest this is the case. And I just never even consider that is a possibility. I would also say today we understand so much about the neocortex. we have made tremendous progress in the last few years that I no longer think of it as an open question. The answers are very clear to me, and the pieces that we know we do not know are clear to me. But the framework is all there and it is like, oh, OK, we are going to be able to do this.
This is not a problem anymore. Just takes time and effort. But there is no mystery, big mystery anymore.
So then let us get into it for for people like myself who are not. Very well versed in the human brain except my own. Uh, can you describe to me at the highest level what are the different parts of the human brain and then zooming in on the neocortex, the parts of the neocortex and so on? A quick overview. Yeah, sure.
The human brain, we can divide it roughly into two parts. there is the old parts, lots of pieces. And then there is a new part, the new partisan neocortex. it is new because it did not exist before mammals. The only mammals have a neocortex in humans. And primates is very large in the human brain. The neocortex occupies about 70 to 75 percent of the volume of the brain.
it is huge.
And the old parts of the brain are, ah, there is lots of pieces there. there is a spinal cord and there is the brain stem and the cerebellum and the different parts of the basal ganglia and so on.
In the old parts of the brain, you have the autonomic regulation like breathing and heart rate. You have basic behaviors. So like walking and running are controlled by the old parts of the brain, all the emotional centers of the brain or in the old part of the brain. When you feel anger, hungry, lost with things like that, those are all in the old parts of the brain.
And and we associate with the neocortex all the things we think about as sort of high level perception and cognitive functions, anything from seeing and hearing and touching things to language to mathematics and engineering and science and so on. Those are all in the neocortex and they are certainly correlated. Our abilities in those regards are correlated with the relative size of our neocortex compared to other mammals.
So that is like the rough division.
And you obviously can not understand the neocortex completely isolated, but you can understand a lot of it with just a few interfaces to the old parts of the brain.
And so it gives you a system to study. The other remarkable thing about the neocortex compared to the old parts of the brain as the neocortex is extremely uniform.
it is not visually or anatomically or it is very it is like I always like to say, it is like the size of a dinner napkin about two and a half millimeters thick. And it looks remarkably the same everywhere. Everywhere you look in that two and a half millimeters is this detailed architecture. And it looks remarkably the same everywhere. And that is across species of mouse versus a cat and a dog and a human where if you look at the old parts of the brain, there is lots of little pieces do specific things.
So it is like the old parts of the brain evolved. This is the part that controls heart rate and this is the part that controls this. And this is this kind of thing. And that is this kind of thing. And these evolved for eons, a long, long time. And they have the specific functions and all certain mammals come along and they got this thing called the neocortex, and it got large by just replicating the same thing over and over and over again.
This is like, wow, this is incredible. So all the evidence we have and this is an idea that was first articulated in a very cogent and beautiful argument by a guy named Vernon Mountcastle in nineteen seventy eight, I think it was that the neocortex all works on the same principle. So language, hearing, touch, vision, engineering, all these things are basically underlying all built in the same computational substrate. they are really all the same problem for the low level.
The building blocks all look similar and they are not even that low level. we are not talking about like like neurons. we are talking about this very complex circuit that exists throughout the neocortex is remarkably similar. It is. it is like, yes, you see variations of it here and there, more of the cell and so on. But what Mountcastle argued was it says, you know, if you take a section of neocortex, why is one a visual area and one is a auditory area or why?
And his answer was, is because one is connected to eyes and one is connected ears, literally. You mean just its most closest in terms of the number of connections to sensor?
Literally, if you took the optic nerve and attached to a different part of the cortex, that part would become a visual region. This actually this experiment was actually done by Morgan, a boy in in in developing.
I think it was lemurs. I can not remember it was some animal. And and there is a lot of evidence to this. You know, if you take a blind person, a person is born blind at birth. They they are born with a visual neocortex. It does not may not get any input from the eyes because of some congenital defect or something.
And that region does something else. It picks up another task. So and it is so it is just it is this very complex thing. it is not like, oh, they are all built on neurons. No, they are all built in this very complex circuit. And and somehow that circuit underlies everything.
And so this is the it is called the common cortical algorithm, if you will. Some scientists just find it hard to believe and they just can not believe that is true. But the evidence is overwhelming in this case.
And so a large part of what it means to figure out how the brain creates intelligence and what is intelligence in the in the in the brain is to understand what that circuit does. If you can figure out what that circuit does, as amazing as it is, then you can then then you understand what all these other cognitive functions are.
So if you were to sort of put neocortex outside of your book on intelligence, if you wrote a giant tome, a textbook on the neocortex, and you look maybe a couple of centuries from now, how much of what we know now would still be accurate two centuries from now?
So how close are we in terms of so understanding? I am going to I have to speak from my own particular experience here.
So I run a small research lab here. it is it is it is like any other research lab. I am sort of the investigator of those actually two of us. And there is a bunch of other people. And this is what we do. We started the neocortex and we published our results and so on. So about three years ago. We had a real breakthrough in this in this film, just tremendous spectrum we started with now published, I think, three papers on it.
And so I have I have a pretty good understanding of all the pieces and what we are missing. I would say that.
Almost all the empirical data we have collected about the brain, which is enormous, if you do not know the neuroscience literature, it is just incredibly. Big and it is for the most part, all correct, it is facts and and experimental results and measurements and all kinds of stuff, but none of that has been really assimilated into a theoretical framework. Right. it is it is data without in the in the language of Thomas Kuhn, the historian, would be a sort of a pre paradigm science, lots of data, but a way to fit in together.
I think almost all of that is correct. Is going to be some mistakes in there. And for the most part, there are not really good, cogent theories about how to put it together. it is not like we have two or three competing good theories which ones are right and which ones are wrong. it is like people just like scratching their heads wrong things. You know, some people have given up on trying to figure out what the whole thing does, in fact, is very, very few labs that that we do that focus really on theory and all this unassimilated data and trying to explain it.
So it is not like we have we have got it wrong. it is just that we have not got it at all.
So it is really, I would say, pretty early days in terms of understanding the fundamental theories forces of the way our mind works.
I do not think so. That I would have said that is true five years ago. So, as I said, we have some really big breakthroughs on this recently and we started publishing papers on this, so we will get we will get to that.
But so I do not think it is you know, I am an optimist. And from where I sit today, most people would disagree with this.
But from where I sit today, from what I know, it is not super early days anymore. We are it is you know, the way these things go is it is not a linear path, right? You do not just start accumulating and get better and better and better know all the stuff you have collected. None of it makes sense. All these things are just starting around. And then you are going to have some breaking point. Oh, my God. Now we got it right.
that is how it goes.
And science and I personally feel like we passed that little thing about a couple of years ago, all that big thing a couple of years ago. So we can talk about that. Time will tell if I am right, but I feel very confident about it.
that is one going to say it on tape like these. Very optimistic. So let us before those few years ago, let us take a step back to stem the hierarchical temporal memory theory, which you first proposed on intelligence and went through a few different generations. You describe what it is, how it evolved through the three generations since you first put it on paper.
Yeah. So one of the things that neuroscientists just sort of missed for many, many years and and especially people for thinking about theory was the nature of time in the brain.
Brains process information through time. The information coming into the brain is constantly changing the patterns. For my speech right now, if you are listening to it at normal speed would be changing on average about every 10 milliseconds or so. you would have to change this constant flow. When you look at the world, your eyes are moving constantly three to five times a second and input completely, completely. If I were to touch something like a coffee cup as I move, my fingers change.
So this idea that the brain works on time changing patterns is almost completely it was almost completely missing from a lot of the basic theories, like here is a vision. it is almost like, oh, no, we are going to put this image in front of you and flash it and say, what is it? Right. Convolutional neural networks work that way today. Right. You know, classify this picture. But that is not what visions like vision is. This sort of crazy time-based pattern that is going all over the place and so is touch and so is hearing.
So the first part of a hierarchical temporal memory was the temporal part is to say you do not understand the brain, really understand intelligent machines unless you are dealing with time-based patterns.
The second thing was the memory component of it was, is to say that we are not just processing input. We learn a model of the world and the memory stands for that model. We have to the point of the brain, part of the neocortex, it learns a model of the world. We have to store things, our experiences in a form that leads to a model the world so we can move around the world, we can pick things up and do things.
Now we know how it is going on. So that is that is what the memory referred to. And many people just they were thinking about like certain processes without memory at all, just like processing things. And then finally, the hierarchical component was a reflection to that. The neocortex, although it is just uniform sheet of cells and parts of it, project to other parts which reject other parts. And there is a sort of rough hierarchy in terms of that.
So the high temporal memory is just saying, look, we should be thinking about the brain as time based, you know, model memory based and hierarchical processing. And and that was a placeholder for a bunch of components that we would then plug into that. We still believe all those things I just said. But we now know so much more that I am stopping the use the word Hiriko. No, remember. Yeah, because it is insufficient to capture the stuff we know.
So again, it is not incorrect, but it is I now know more and I would rather describe it more accurately. Yeah. So you are basically we can think of GM as emphasizing that there is three aspects of intelligence that are important to think about, whatever the whatever the eventual theory converges to. Yeah. So in terms of time, how do you think of nature of time across different time scales? You mentioned things changing, sensory input, changing every 10 minutes or about every few minutes, every few months.
Well, if you think about a neuroscience problem, the brain problem, neurons themselves can stay active for certain periods of time. They can parts of the brain with this doctor for minutes, you know, so you could hold up a certain perception or an activity for a certain period of time. But not most of them do not last that long. And so if you think about your thoughts, are the activity neurons, if you are going to want to involve something that happened a long time ago, mean even just this morning, for example, the neurons have not been active throughout that time.
So you have to store that. So if I ask you, what did you have for breakfast today? That is memory. That is you have built into your model the world that you remember. And that memory is in the in the synopsis, especially in the formation of synapses. And so it is you are sliding into what you know is two different time scales. There are time scales at which we are understanding my language and moving about and seeing things rapidly over time.
that is the time scales of activities of neurons. But if you want to get longer time scales, then it is more memory. And we have to invoke those memories to say, oh, yes, well, now I can remember what I had for breakfast because I stored that someplace. I may forget it tomorrow, but it is stored for now.
So this memory also need to have. So the hierarchical aspect of reality is not just about concepts, it is also about time. Do you think of it that way?
Yeah, time is infused in everything. it is like you really can not separate it out.
If I ask you what is what is your how does the brain learn a model of this coffee cup here?
A coffee cup of coffee cup.
I said, well, time is not an inherent property of the model. I have this cup, whether it is a visual model or tactile model, I can sense it through time. But the model itself does not have that much time. If I asked you if I said, well, what is the model of my cell phone?
My brain has learned a model of a cell phone. So if you have a smartphone like this and I said, well, this has time aspects to it, I have expectations when I turn it on, what is going to happen, what, what or how long it is going to take to do certain things. But I bring up an app. What sequence is so I have it. And it is like melodies in the world. You know, the melody has a sense of time.
So many things in the world move and act, and there is a sense of time related to them. Some do not, but most things do actually. So it is sort of infused throughout the models of the world. You build a model, the world you are learning the structure of the objects in the world, and you are also learning how those things change through time.
OK, so it is it is it really is just the fourth dimension that is infused deeply. And you have to make sure that your models of intelligence incorporate it.
So like you mentioned, the state of neuroscience is deeply empirical.
A lot of data collection. it is you know that that is where it is. Schoon, right? Yeah. And then you are proposing a theory of intelligence and which is really the next step, the really important step to take.
But why why is HTM or what we will talk about soon the right theory.
So is it more is it backed by intuition? Is it backed by evidence? Is it backed by a mixture of both? Is it kind of closer to where string theory is in physics, where there is mathematical components which show that, you know what, it seems that this is fits together too well for it not to be true, which is what we are string theory is, is that we are the of all those things, although definitely where we are right now, it is definitely much more on the empirical side than, let us say, string theory.
The way this goes about, we are theorist's right? So we look at all this data and we are trying to come up with some sort of model that explains it basically. And this year, unlike string theory, there is vast amounts of empirical data here that I think than most physicists deal with.
And so our challenge is to sort through that and figure out what kind of constructs would explain this, and when we have an idea, you come up with the theory of some sort.
You have lots of ways of testing it. First of all, I you know, there are a hundred years of assimilated, unassimilated empirical data for neuroscience. So we go back and read papers and we say, oh, did someone find this already with you? We can predict X, Y and Z, and maybe no one's even talked about it since nineteen seventy two or something.
But we go back and find and we say, oh either it can support the theory or it can invalidate the theory. And we say, OK, we have to start over again. Oh no, it is the poor, let us keep going with that one.
So the way I kind of view it when we do our work, we come up, we we look at all this empirical data and it is it is what I call it is a set of constraints.
we are not interested in something that is biologically inspired.
we are trying to figure out how the actual brain works. So every piece of empirical data is a constraint on a theory. In theory, if you have the correct theory, it needs to explain everything. Right. So we have this huge number of constraints on the problem, which initially makes it very, very difficult. If you do not have any constraints, you can make up stuff all the day. You know, like here is an answer on how you can do this.
You can do that, you can do this. But if you consider all biology as a set of constraints on neuroscience, a set of constraints, and even if you are working in one little part of the neocortex, for example, there are hundreds and hundreds of constraints.
These are empirical constraints that it is very, very difficult initially to come up with a theoretical framework for that.
But when you do and it solves all those constraints at once, you have a high confidence that you have got something close to correct.
it is just mathematically almost impossible not to be right.
So that is the the kerson, the advantage of what we have, the cursives we have to solve, we have to meet all these constraints, which is really hard.
But when you do meet them, then you have a great confidence that you discover something. In addition, then we work with scientific labs. So we will say, oh, there is something we can not find. We can predict something, but we can not find it anywhere in the literature. So we will then we have people we collaborated with. we will say sometimes they will say, you know, I have some collected data which I did not publish, but we can go back and look at it and see if we can find that, which is much easier than designing a new experiment.
You know, new neuroscience experiments take a long time years. So although some people are doing that now, too. So but between all of these things, I think it is a reasonable it is actually a very, very good approach. We are blessed with the fact that we can test our theories out the ying yang here because there is so much unassimilable data. And we can also falsify our theories right. Easily, which we do often.
So it is kind of reminiscent to whenever whenever that was with Copernicus. You know, when you figure out that the sun is at the center, the the solar system, as opposed to Earth, the pieces just fall into place.
Yeah, I think that is the general nature of AHA moments is in Copernicus. It could be you could say the same thing about Darwin, you could say the same thing about, you know, about the double helix that that people have been working on a problem for so long and have all this data and they can not make sense of it.
They can not make sense of it. But when the answer comes to you and everything falls into place, it is like, oh, my gosh, that is it. that is got to be right. I asked both Jim Watson and Francis Crick about this. I asked them, you know, when you were working on trying to discover the structure of the double helix and when you came up with the sort of the structure that ended up being correct. But it was sort of a guess, you know, it was not really verified yet.
I said, did you know that it was right? And they both said, absolutely, we absolutely knew it was right. And it does not matter if other people did not believe it or not. We knew it was right.
they would get around the thing and agree with it eventually anyway.
And that is the kind of thing you hear a lot with scientists who who really are studying a difficult problem. And I feel that way, too, about our work.
Have you talked to Krikor Watson about the problem you are trying to solve, the idea of finding the DNA of the brain?
Yeah, in fact, Francis Crick was very interested in this in the latter part of his life. And in fact, I got interested in brains by reading an essay he wrote in 1979 called Thinking about the Brain. And that is when I decided I am going to leave my profession of computers in engineering and become a neuroscientist.
Just reading that one essay from Francis Crick, I got to meet him later in life.
I got to I spoke at the Salk Institute and he was in the audience. And then I had a chat with him afterwards.
He was interested in a different problem. He was he was focused on consciousness and easy.
Well, I think it is a red herring, and so we were not really overlapping a lot there. Jim Watson, who is still alive, is is also interested in this problem. And he was when he was director of the Boston Harbor Laboratories, he was really sort of behind moving in the direction of neuroscience there. And so he had a personal interest in this field. And I have met with him numerous times. And in fact, the last time was a little bit over a year ago.
I gave a talk, Cosmin Harbor Labs, about the progress we were making in in our work. And it was a lot of fun because he said, well, you would not be coming here unless you had something important to say. So I am going to go to talk. So he sat in the very front row next to me.
Next to him was the director of the lab, Bruce Stillman. So these guys were in the front row of this auditorium, right. So nobody else in the auditorium was to sit in the front row because as Jim Watson is the director and and I gave a talk and I had dinner with Jim afterwards, but there is a great picture of my colleagues who the him how to where I am up there sort of explaining the basics of this new framework we have. And Jim Watson's on the edge of his chair.
he is literally on the edge of his chair, like intently staring up at the screen. And when he discovered the structure of DNA, the first public talk he gave was a cold Spring Harbor lapse.
So and there is a picture of this famous picture of Jim Watson standing at the whiteboard with over it saying, pointing at something with the a double helix with pointer. And it actually looks a lot like the picture of me. So there was a sort of funny I am talking about the brain and there is Jim Watson staring intently at. And of course, there were, you know, whatever, 60 years earlier he was standing, you know, pointing at the double helix.
And that is one of the great discoveries in all of, you know, whatever biology, science, all science.
So this is the funny that there is echoes of that in your presentation. Do you think, in terms of evolutionary timeline and history, the development of the neocortex was a big leap, or is it just a small step? So like if we ran the whole thing over again from the from the birth of life on Earth, how could we develop the mechanism?
Well, those are two separate questions. One is, was it a big leap? And one was how like it is, OK, they are not necessarily related, maybe correlated or they maybe not.
We do not really have enough data to make a judgment about that. I would say definitely was a big leap. But I can tell you why. I think I do not think it was just another incremental step.
I think at that moment I do not really have any idea how likely it is.
If we look at evolution, we have one data point, which is earth right. Life formed on Earth billions of years ago, whether it was introduced here or created here or someone introduced it, we do not really know. But it was here early. It took a long, long time to get to multicellular life. And then from ultimately TELESTAR life, it took a long, long time to get this neocortex. And we have only had the new architectures for a few hundred thousand years.
So that is like nothing. OK, so is it likely?
Well, it certainly is not something that happened right away on Earth and there are multiple steps to get there. So I would say it is probably not something that would happen instantaneously on other planets that might have life. It might take several billion years on average. Is it likely? I do not know. But you would have to survive for several billion years to find out probably.
Is it a big leap? Yeah, I think it is it is a qualitative difference in all other evolutionary steps. I can try to describe that, if you would like.
Sure. In which. In which way? Yeah, I can tell you how pretty much.
Yeah. let us talk a little preface. Many of the things that humans are able to do do not have obvious survival advantages, precedent.
You know, we create music. Is that is there really a survival advantage to that? And maybe maybe not. What about mathematics? Is there a real survival advantage to mathematics?
Well, we could stretch you can try to figure these things out. Right. But, um, but mostly evolutionary history. Everything had immediate survival advantages to it.
So I will tell you a story which I like may or may not be true, but the story goes as follows. Organisms have been evolving for since the beginning of life here on Earth. And I think this sort of complexity onto that, this sort of complexity and the brain itself is evolved this way. In fact, there is an old part in older parts, an older, older part of the brain that kind of just keeps climbing on new things and we keep adding capabilities and we got to the neocortex.
Initially, it had a very clear survival advantage in that it. Better vision and better hearing and better touch and so on, but what I think happens is that evolution just took took a mechanism and this is in our recent theories, but it took a mechanism involved a long time ago for navigating in the world, for knowing where you are. These are the so-called grid cells in place, cells of an old part of the brain. And it took that mechanism for building maps of the world and knowing where you are on those maps and how to navigate those maps and turns it into a sort of a slimmed down, idealized version of it.
And that idealized version could now apply to building maps of other things, maps of coffee, cups and maps of phones, maps of, you know, some of the concepts.
Yes. And not just almost. Exactly.
And and so you just started replicating this stuff, right. You just think more and more and more of it. So we went from being sort of dedicated purpose, neural hardware to solve certain problems that are important to survival, to a general purpose, neural hardware that could be applied to all problems.
And now it is escaped the orbit of survival. it is we are now able to apply it to things which we find enjoyment, you know, but are not really clearly survival characteristics, and that it seems to only have happened in humans to the large extent. And so that is what is going on.
We sort of have we have sort of escape the gravity of evolutionary pressure in some sense in the neocortex and now does things which not that are really interesting discovery models of the universe, which may not really help us. does not matter how is the help of surviving, knowing that there might be multiverses or there might be, you know, the age of the universe or how do you know various things occur?
It does not really help us survive at all, but we enjoy it. And that is what happened, or at least not in the obvious way.
Perhaps it is required. If you look at the entire universe in an evolutionary way, it is required for us to do interplanetary travel and therefore survive past our own sun. But let us not get too.
But, you know, evolution works at one time frame and it is survival. If you think of survival of the phenotype, survival of the individual. Exactly what you are talking about there is spans well beyond that. So there is no genetic I am not transferring any genetic traits to my children that are going to help them survive better on Mars. Right.
Totally different mechanism. So let us get into the new, as you have mentioned, this idea. I do not know if you have a nice name. They call it the thousand brain theory I have told. I like it.
So can you talk about the the idea of spatial view concepts and so on? Yeah.
So can I just describe sort of there is an underlying core discovery which then everything comes from that.
it is a very simple this is really what happened.
We were deep into problems about understanding how we build models of stuff in the world and how we make predictions about things. And I was holding a coffee cup just like this in my hand and I had my finger was touching the side, my index finger, and I moved it to the top and I was going to feel the rim at the top of the cup. And I asked myself a very simple question. I said, well, first of all, I say, I know that my brain predicts what it is going to feel before it touches it.
You can just think about it and imagine it. And so we know that the brain is making predictions all the time.
So the question is, what does it take to predict that? Right. And there is a very interesting answer. First of all, it says the brain has to know it is touching a coffee cup. It has to have a model, a coffee cup and need to know where the finger currently is on the cup relative to the cup.
Because when I make a movement and you know where it is going to be on the Cup after the movement is completed relative to the cup, and then it can make a prediction about what going to sense. So this told me that the neocortex, which is making this prediction, need to know that it is sensing it is touching a cup and it needs to know the location of my finger relative to that cup in a reference frame of the cup. It does not have the World Cup as well.
To my body, it does not matter its orientation. None of that matters. it is where my finger is relative to the cup, which tells me then that the neocortex is has a reference frame that is anchored to the Cup because otherwise it would not be able to say the location and I would not be able to predict my new location. And then we quickly, very instantly, instantly, you can say, well, every part of my skin could touch this cup and therefore every part of my skin is making predictions and every part of my skin must have a reference frame that it is using to make predictions.
So the big idea is that throughout the neocortex, there are everything is being is being stored and referenced in reference frames. You can think of like X, Y, Z reference things, but they are not like that. We know a lot about the neural mechanisms for this, but the brain thinks in reference frames. And as an engineer, if you are an engineer, this is not surprising.
You say if I wanted to build a a cad model of the coffee cup, I would bring it up in some CAD software and I would assign some reference to him and say this features of dislocations and so on. But the fact that this idea that this is occurring throughout the neocortex, everywhere, it was a novel idea and and then a zillion things fell into place after that was doing so.
Now we think about the neocortex as processing information quite differently than we used to do it. We used to think about the neocortex as processing sensory data and extracting features from that sensory data and then extracting features from the features very much like a deep learning network to us today.
But that is not how the brain works at all. The brain works by assigning everything, every input, everything to reference frames. And there are thousands, hundreds of thousands of them active at once in your neocortex.
it is a surprising thing to think about, but once you sort of internalize this, you understand that it explains almost every all the almost all the mystery had about this, about the structure. So one of the consequences of that is that every small part of the neocortex a millimetre square and there is one hundred and fifty thousand of those. So it is about one thousand square millimeters. If you take every little square millimeter of the cortex, it is got some input coming into it.
And it is going to have reference frames where it is a sign that input, too, and each square millimeter can learn complete models of objects.
So what I mean by that, if I am touching the coffee cup, well, if I just touch it in one place, I can not learn what this coffee cup is because I am just feeling one part. But if I move it around the cup and touch it in different areas, I can build up a complete model of the cup because I am now filling in that three dimensional map, which is the coffee cup. I can say, oh, what do I feeling it all these different locations.
that is the basic idea. it is more complicated than that. But so through time and we talked about time earlier, through time, even a single column which is only looking at or a single part of the cortex, it is only looking at a small part of the world can build up a complete model of an object. So if you think about the part of the brain which is getting input from all my fingers, so they are spread across the top of head here, this is the somatosensory cortex.
there is columns associated of all the different areas of my skin.
And what we believe is happening is that all of them are building models of this, every one of them or things not they are not all building all not every column. Every part of the cortex builds models of everything, but they are all building models of something.
And and so you have so when I when I touched this cup with my hand, there are multiple models of the cup being invoked. If I look at it with my eyes there again, many models of the cup being invoked because it is part of the visual system. The brain does not process an image. that is that is a misleading idea. it is just like your fingers touching the cups of different parts of my retina, looking at different parts of the cup. And thousands and thousands of models of the cup are being invoked at once.
And they are all voting with each other, trying to figure out what is going on. So that is why we call it the thousand brain theory of intelligence, because there is not one model of the cup. There are thousands of models that this cup. There are thousands of models of your cell phone and about cameras and microphones and so on. it is a distributed modeling system, which is very different than what people have thought about it.
So that is a really compelling and interesting idea of two first questions. The one on the ensemble, part of everything coming together. You have these thousand brains. How how do you know which one has done the best job of forming the great question.
Let me try explain.
there is a problem that is known in neuroscience called the sense of fusion problem. Yes.
And so the idea is of something like, oh, the image comes from the eye. there is a picture on the retina and it gets projected to the neocortex.
Oh, by now it is all spread out all over the place. And it is kind of squirrelly and distorted and pieces are all over know it does not look like a picture anymore.
When does it all come back together again? Right.
Or you might say, well, yes, but I also I also have sounds or touches associative, so I am seeing the cup and touching the cup. How do they get combined together again? So this is called the sensor fusion problem, as if all these disparate parts have to be brought together into one model someplace.
that is the wrong idea. The right idea is that you got all these guys voting. there is auditory models of the visual models, the the tactile models of the cup. There are one individual system. There might be ones that are more focused on black and white ones, version on color. It does not really matter. there is just thousands and thousands of models of this cup and they vote. They do not actually come together in one spot. Just literally think of it this way.
Imagine you have these columns are like about the size of a little piece of spaghetti, like a two and a half millimeters tall and about a millimetre in mind. they are not physical like. But you can think of them that way. And each one's trying to guess what this thing is. we are touching now. They can they can do a pretty good job if they are allowed to move over time.
So I could reach my hand into a black box and move my finger around an object.
And if I touch enough pieces like, OK, I know I know what it is, but often we do not do that.
Often I can just reach and grab something with my hand all at once. I get it. Or if I had to look through the world through a straw. So I am invoking one little column, I can only see a part of something. I have to move the straw around. But if I open my eyes, I see the whole thing at once. So what we think is going on, it is all these little pieces of spaghetti, if you will, all these little columns in the cortex or all trying to guess what it is that they are sensing.
they will do a better guess if they have time and can move over time. So if I move my eyes or my fingers, but if they do not, they have a they have a poor guess. it is a it is a probabilistic guess of what they might be touching.
Now imagine they can post their probability at the top a little piece of spaghetti. Each one of them says, I think and it is not really a probability institution. it is more like a set of possibilities in the brain. It does not work as a problem. The distribution works is more like what we call a union, you could say.
And one comment is, I think it could be a coffee cup, soda can or a water bottle, another Comtesse. I think it could be a coffee cup or telephone or camera or whatever.
Right. And all these guys are saying what they think it might be. And there is these long range connections in certain layers in the cortex. So there is some layers in some cell types in each column send the projections across the brain and that is the voting occurs. And so there is a simple associative memory mechanism.
we have described this in a recent paper and we have modeled this that says they can all quickly settle on the only or the one best answer for all of them. If there is a single best answer, they all vote and say, yeah, it is got to be the coffee cup. And at that point, they all know it is a coffee cup. And at that point, everyone acts as if it is the coffee cup that we know it is coffee. Even though I have only seen one little piece of this world.
I know it is coffee cup I am touching or I am seeing or whatever.
And so you can think of all these columns are looking at different parts in different places, different sensory input, different locations. they are all different. But this layer that is doing the voting, that is it solidifies. it is just like crystalizes and says, oh, we all know what we are doing. And so you do not bring these models together in one model, you just vote and there is a crystallization of the vote.
Great that at least a compelling way to think about. About the way you form a model of the world now, you talk about a coffee cup. Do you see this? As far as I understand, you are proposing this as well, that this extends to much more than coffee cups? Yeah, that it does.
Or at least the physical world. It expands to the world of concepts. Yeah, it does.
And well, the first the prima facie evidence for that is that the regions of the neocortex that are associated with language or high level thought or mathematics or things like that, they look like the regions of the neocortex that process vision, hearing and touch that they do not look any different or they look only marginally different. And so one would say, well, if Vernin Mountcastle, who proposed it all the all the parts of the cortex doing the same thing, if he is right, then the parts that doing language or mathematics and physics are working on the same principle.
They must be working on the principle of reference frames. So that is a little odd thought. But of course, we had no we had no prior idea how these things happen. So let us go with that.
And we in our recent paper, we talked a little bit about that.
I have been working on it more since. I have better ideas about it. Now I am sitting here. I am very confident that that is what is happening. And I can give you some examples that help you think about that. it is not we understand it completely, but I understand it better than I have described it in any paper so far.
So but we did put that idea out there, says, OK, this is it. it is a good place to start, you know, and the evidence would suggest that is how it is happening. And then we can start tackling that problem in one piece of time. Like what does it mean to do high level thought, what it means to do language? How would that fit into a reference frame framework?
So there is a and if you could tell me if there is a connection, but there is an app called Anqi that helps you remember different concepts and they talk about like a memory palace that helps you remember completely random concepts by sort of trying to put them in a physical space in your mind and putting them next to each other. The method of Lokey look that for some reason that seems to work really well. Yeah. Now, that is a very narrow kind of application of just remembering some fact.
But that is that is a very, very telling one. Yes, exactly. So it seems like you are describing a mechanism why this seems to work.
So so basically, the way what we think is going on is all things, you know, all concepts, all ideas, words, everything, you know, are stored in reference frames.
And and so if you want to remember something, you have to basically navigate through a reference frame, the same way a rat navigates to in the same way my finger navigates to this coffee cup. You are moving through some space. And so what? You have a random list of things, which is to remember by assigning him to a reference frame, you have already know very well it is your house, right? Idea. The method Loki's, you can say, OK, in my lobby, I am going to put this thing and then and then the bedroom, I put this one, I go down the hall, I put this thing, and then you want to recall those facts.
So we call the things. You just walk mentally, you walk through your house, you are mentally moving through a reference frame that you already had. And that tells you there is two things that are really important about it. It tells us the brain prefers to store things in reference frames and that the method of recalling things or thinking, if you will, is to move mentally through those reference frames. You can move physically through some reference frames, like I could physically move for the reference movement, this coffee cup.
I can also mentally move through the reference from the coffee cup, imagining me touching it.
But I can also mentally move my house. And and so now we can ask ourselves, are all concepts stored this way? There was some recent research using human subjects in fMRI, and I am going apologize for not knowing the name of the scientist who did this.
But what they did is they they put humans in this fMRI machine, which is one of these imaging machines, and they they gave the humans tasks to think about birds. So they had different types of birds and look big and small and longnecks long like things like that. And what they could tell from the MRI was a very clever experiment. Get to tell when humans were thinking about the birds, that the birds, the knowledge of birds was arranged in a reference frame similar to the ones that are used when you navigate in a room.
These are called grid cells. And there are grid cell like patterns of activity in the neocortex when they do this.
So that it is a very clever experiment, you know, and what it basically says that even when you are thinking about something abstract and you are not really thinking about it as a reference frame, it tells us the brain is actually using a reference frame and it is using the same neural mechanisms, these grid sort of the basic same neuro mechanisms that we have we have proposed that grid cells which exist in the old part of the brain, the anterior cortex, that that mechanism is now similar mechanisms is used throughout the neocortex.
it is the same nature preserve this interesting way of creating reference frames.
And so now they have empirical evidence that when you think about concepts like birds, that you are using reference frames that are built on grid cells. So that is similar to the method of low carb in this case, the birds are related, so it makes they create their own reference frame, which is consistent with bird space.
And when you think about something, you go through that you can make the same example. let us take a math. Mathematics, right.
let us say you want to prove a conjecture. OK, what is the conjecture? Conjecture is a statement you believe to be true, but you have not proven it. And so it might be an equation. I want to show that this is equal to that. And you have you have some places you start with. You said, well, I know this is true and I know this is true. And I think that maybe to get to the final proof, I need to go through some intermediate results.
What I believe is happening is literally these equations or these points are assigned to a reference frame, a mathematical reference frame.
And when you do mathematical operations, a simple one might be multiply or divide, but you might be able to transform or something else that is like a movement in the reference frame of the math.
And so you are literally trying to discover a path from one location to another location in a space of mathematics. And if you can get to these intermediate results, then, you know, your map is pretty good and you know, you are using the right operations.
Much of what we think about is solving hard problems is designing the correct reference frame for that problem, figuring out how to organize the information and what behaviors I want to use in that space to get me there.
So if you dig in an idea, this reference frame, whether it is the math, you start a set of axioms to try to get to proving the conjecture. Can you try to describe maybe take a step back how you think of the reference frame, that context is? Is it the reference frame that the axioms are happy in? Is that the reference frame that might contain everything? Is that a changing thing? Do you have many, many reference frames?
I mean, the way the theory, the thousand brains of intelligence does, that every single thing in the world has its own reference frame. So every word has its own reference names. And we can talk about this, the mathematics work out. This is no problem for neurons to do this.
But how many references is the coffee cup have? Well, it is on a table.
let us say you ask how many reference frame could the column in my finger that is touching the coffee cup?
Because there are many, many there are many, many models of the coffee cup. So the coffee there is no one model, the coffee cup. There are many miles of coffee cup.
And you could say, well, how many different things can my finger learn is the question you want to ask. Imagine I say every concept, every idea, everything you have ever know about that. You can say, I know that thing has a reference name associated with it.
And what we do when we build composite objects, we we assign reference frames to points, another reference frame. So my coffee cup has multiple components to it. it is got a limb, it is got a cylinder, it is got a handle. And those things that have their own reference frames and they are assigned to a master reference frame, which is called this cup. And now I have this Numenta logo on it. that is something that exists elsewhere in the world. it is its own thing.
So it has its own reference frame. So we now have to say, how can I sign the new logo reference frame onto the cylinder or onto the coffee cup?
So it is all we talked about this in the paper that came out in December of last year, that idea of how you can find reference frames of reference frames, how neurons could do this.
So my question is, even though you mentioned reference frames a lot, I almost feel it is really useful to dig in to how you think of what a reference frame is. I mean, it was already helpful for me to that. You think of reference frames as something there is a lot of.
OK, so let us just say that we are going to have some neurons in the brain, not many, actually. Ten thousand. Twenty thousand are going to create a whole bunch of reference frames. What does it mean? What is the reference?
First of all, these reference names are different than the ones you might be used to that we know lots of references. For example, we know the Cartesian coordinates, X, Y, Z. that is a type of reference frame. We know longitude and latitude. that is a different type of reference frame. If I look at a printed map, it might have columns A through M and rows one through 20. that is a different type of reference frame. it is a kind of a Cartesian reference frame.
The interesting thing about the reference frames in the brain, and we know this because these have been established through neuroscience, studying the enteron cortex.
So I am not speculating here because this is known neuroscience in an old part of the brain, the way these cells create reference frames, they have no origin. So what it is more like you have you have a point, a point in some space and you give a particular movement. You can then tell what the next point should be and you can then tell what the next point would be and so on. You can use this to to calculate how to get from one point to another.
So how do I get from my house to my home or how do I get my finger from the side of my cup to the top of the cup?
How do I get from the axioms to the to the conjecture?
So it is a different type of reference frame, and I can if you want, I can describe in more detail, I can paint a picture how you might want to think about that.
Really helpful to think it is something you can move through. Yeah, but is there is it is it helpful to think of it as spatial in some sense or is there something. Oh, it is definitely spatial.
it is spatial in a mathematical sense. How many dimensions can it be crazy. No.
Well, that is an interesting question in the old part of the brain, the answer on the cortex, they studied rats and initially it looks like, oh, this is just two dimensional. it is like the rat is in some box in the maze or whatever, and they know where the rat is using these two dimensional reference frame to know where it is in the maze.
We said, OK, well, what about what about bats? that is a mammal. And they fly in three dimensional space. How do they do that? They seem to know where they are. Right. So this is a current area of active research and it seems like somehow the neurons in the enteron cortex can learn three dimensional space. We just two members of our team, along with effect from MIT, just released a paper this literally last week.
it is an archive where they show that you can if you way these things work. And I will not get unless you want to, I will not get into the detail.
But grid cells can represent any and dimensional space. it is not inherently limited. You can think of it this way. If you had two dimensional, the way it works is you had a bunch of two dimensional slices. that is the way these things work. there is a whole bunch of two dimensional models and you can just you can slice up any and dimensional space and with two dimensional projections. So and you could have one dimensional model. So there is there is nothing inherent about the mathematics, about the way the neurons do this, which which constrain the dimensionality of the space, which I think was important.
So obviously, I have a three dimensional map of this cup, maybe even more than that, I do not know. But it is clearly a three dimensional map of the cup. I do not just have a projection of the cup, but when I think about birds and when I think about mathematics, perhaps it is more than three dimensions are not.
So in terms of each individual column building up more and more information over time, do you think that mechanism is well understood in your mind? you have proposed a lot of architectures there. Is that a key piece or is it is the big piece, the thousand brain theory of intelligence, the ensemble of it all? Well, I think they are both big.
I mean, clearly, the concept as a theorist, the concept is most exciting. Right?
We had a little high level concept. This is a totally new way of thinking about the new tricks work. So that is appealing. It has all these ramifications. And with that as a framework for how the brain works, you can make all kinds of predictions and solve all kinds of problems. Now, we are trying to work through many of these details right now. OK, how are the neurons actually do this? Well, it turns out if you think about grid cells and place cells in the old parts of the brain, there is a lot that is known about it.
But there is still some mysteries. there is a lot of debate about exactly the details, how these work and what are the signs. And we have that still the same level of detail, the same level of concern. What we spend here most of our time doing is trying to make a very good list of the things we do not understand yet. that is the key part here. What are the constraints? it is not like, oh, this thing seems work. we are done now.
it is like, OK, it kind of works. But these are other things we know it has to do and it is not doing those yet.
I would say we are well on the way here. we are not done yet. there is a lot of trickiness to this system.
But the basic principles about how different layers in the neocortex are doing much of this, we understand. But there are some fundamental parts that we do not understand.
So what would you say is one of the harder open problems that one of the ones that have been bothering you? Oh, keeping you up at night the most?
Oh, well, right now, this is a detail thing that would not apply to most people. OK, but you want me to ask you.
Yeah, please. we have talked about as if. Oh, to predict what you are going to sense on this coffee cup, I need to know where my finger is going to be on the coffee cup. That is true, but it is insufficient. I think about my finger touches the edge of the coffee cup. My finger can touch it at different orientations. Right. I can rotate my finger around here and that does not change.
I, I can make that prediction in somehow. So it is not just the location. there is an orientation component of this as well. This is known in the old part of the brain to the things called head directions tells which which way the right is facing.
it is the thing kind of basic idea.
So if my finger were a, you know, in three dimensions, I have a three dimensional orientation and I have a three dimensional location. If I was a rat, I would have a I think of a two dimensional location, a two dimensional orientation, a one dimensional orientation. Like just which way is it facing.
So how the the two components work together, how it is it I, I combine orientation, the orientation, my sensor as well as the, the, the location is a tricky problem and I think I have made progress on it. So at a bigger version of that perspective, super interesting, but super specific is are not, you know, that is really good, but there is a more general version of that. Do you think context matters, the fact that we are in a building in North America, that that we in the day and age where we have mugs, I mean, there is all this extra information that you bring to the table about everything else in the room that is outside of just the coffee cup.
How does that get so. Yeah, and that is another really interesting question. I am going to throw that under the rubric or the name of attentional problems.
First of all, we have this model. I have many, many models. And also the question, does it matter? Because, well, it matters for certain things.
Of course it does. Maybe what we think of as a coffee cup in another part of the world is something different. Maybe our logo, which is very benign in this part of the world, it means something very different, another part of the world.
So those things do matter. I think the thing the way to think about it is the following.
One way to think about it is we have all these models of the world, OK? And we model that, we model everything, and as I said earlier, nothing in our models are actually we we build composite structure. So every object is composed of other objects, which are composed of other objects, and they become members of other objects. So this room has chairs and a table in a room and the walls and so on. Now we can just range of these things a certain way.
You go, oh, that is in the conference room. So what we do is when we go around the world and we experience the world, we walk into a room, for example, the first thing I do like, oh, I am in this room, I recognize the room. Then I can say, oh, look, there is a there is a table here and I attending to the table. I am then assigning this table in the context of the room on the table.
there is a coffee cup on the table, there is a logo. And in the logo there is the word Numenta onlooking the logo. there is the letter E on. Look, it has an unusual serve and it does not actually.
But so the point is, you your attention is kind of drilling deep in and out of these nested structures.
And I can pop back up and I could pop back down and pack up and I could pop back down. So when I attend to the coffee cup, I have not lost the context of everything else. But but it is sort of this sort of nested structure.
So the attention filters the reference for information for that particular period of time. Yes.
It basically a moment to moment you attend the subcomponents and then you can tend to subcomponent the subcomponent.
It can move up and down. You can move up and down. Then we do that all the time.
you are not even now that I am aware of it, I am very conscious of it. But most people do not want to think about this.
You know, you do not you just walk in the room and you do not say, oh, I look at the chair and I look at the board and looked at that word on the board. And I looked over here, what is going on right there?
What percentage of your day are you deeply aware of this? And what part can you actually relax and just be?
Jeff, me personally, like my personal day.
Yeah, unfortunately, I am afflicted with too much of the former, I think fortunately or unfortunately.
Yeah. So I do not think it is useful.
Oh, ideas is useful. Totally useful. I think about this stuff almost all the time.
And I am one of my primary ways of thinking is when I am in sleep at night, I always wake up in the middle of night and then I stay awake for at least an hour with my eyes shut in sort of a half sleep state. Thinking about these things, I come up with answers to problems very often in that sort of half sleeping state. I think about on my bike ride, I think about on walks. I am just constantly think about this.
I have to almost schedule time to not think about the stuff because it is very it is mentally taxing.
Are you when you think about the stuff, are you thinking introspectively, like almost taking a step outside of yourself and trying to figure out what is your mind doing?
I do that all the time, but that is not all I do. I am constantly observing myself, so as soon as I started thinking about grid cells, for example, and getting into that, I started saying, oh, well, grid cells have my place a sense in the world, you know, that is where you know where you are. And it is interesting, you know, we always have a sense of where we are in this were lost. And so I started at night when I got up to go to the bathroom, I would start trying to do a complete with my eyes closed all the time.
And I would test my sense of results. I would I would walk, you know, five feet and say, OK, I think I am here.
Am I really there? what is my error? And then I cut my ear again and see how the errors accumulate. So even something as simple as getting up in the middle night to go to the bathroom, I am testing these theories out. it is kind of fun. I mean, the coffee cup is an example of that, too. So I think I find that these sort of everyday intersections are actually quite helpful. It does not mean you can ignore the science.
I mean, I spend hours every day reading ridiculously complex papers. that is not nearly as much fun, but you have to sort of build up those constraints and knowledge about the field and who is doing what and what exactly they think is happening here. And then you can sit back and say, OK, let us try to piece this all together. let us come up with some. You know, I am very in this group here, people, they know they do this.
I do this all the time. I come in with these introspective ideas and say, well, you ever thought about this? Now what?
This all do this together? Yeah. And it is helpful. it is not as long as you do not if you all you did was at dinner, you just making up stuff. Right. But if you are constraining it by the reality, the neuroscience, then it is really helpful.
So let us talk a little bit about deep learning and the successes in the applied space of neural networks, the ideas of training model and on data. And these these simple computational units, neuron artificial neurons that with back propagation, statistical ways of being able to generalize from the training set onto data that is similar to that training center. So where do you think are the limitations of those approaches? What do you think are its strengths relative to your major efforts of constructing a theory of human intelligence?
Yeah, well, I am not an expert in this field. I am somewhat knowledgeable. So but some of it is just your intuition. What are you.
Well, I have a little bit more than intuition, but I want to say, like, you know, one of the things that you asked me, do I spend all my time thinking about neuroscience?
I do that to the exclusion of thinking about things like neural networks.
But I try to stay current. So, look, I think it is great the progress they have made. it is fantastic. And as I mentioned earlier, it is very highly useful for many things. The models that we have today are actually derived from a lot of neuroscience principles. They are distributed processing systems and distributed memory systems, and that is how the brain works.
They use things that we might call them neurons, but they are really not neurons at all.
So we can just they are not really neurons, distributed processing systems and and the nature of hierarchy that came also from neuroscience. And so there is a lot of things, the learning rules, basically not that but other.
But I would be curious to say they are not neurons at all. He described them which way? I mean, some of it is obvious. But I would be curious if if you have specific ways in which you think are the biggest differences.
Yeah, we had a paper in 2016 called Why Neurons Have Thousands of Synapses and it and if you read that paper, you will know what I am talking about here. A real neuron in the brain is a complex thing.
And let us start with the synapses on it, which is the connection between neurons. Real neurons can everywhere from five to thirty thousand synapses on the ones near the cell body, the ones that are close to the SOMO, the cell body.
Those are like the ones the people model in artificial neurons. There is a few hundred of those. Maybe they can affect the cell.
They can make the cell become active. Ninety five percent of the synapses can not do that. they are too far away. So if you accept one of the synapses, it just does not affect the cell body enough to make any difference. Any one of them individually, any one of the or even if you do a mass of them.
What what what real neurons do is the following, if you activate or they get 10 to 20 of them active at the same time, meaning they are all receiving an input at the same time. And those 10 to 20 synapses or 40 cents within a very short distance on the dendrite, like 40 microns, a very small area.
So if you activate a bunch of these right next to each other at some distant place, what happens is it creates what is called the dendritic spike. And then Druidic spike travels through the dendrites and can reach the Soma or the cell body. Now, when it gets there, it changes the voltage, which is sort of like going to make the cell fire, but never enough to make the cell fire is sort of what we call it.
We depolarize the cell.
You raise the voltage a little bit, but not enough to do anything. it is like, well, what good is that? And then it goes back down again. So we proposed a theory, which I am very confident and basics are, is that what is happening there is those. Ninety five percent of the synapses are recognizing dozens to hundreds of unique patterns.
They can, you know, about 10, 20 synopsize at a time and they are acting like predictions. So the neuron actually is a predictive engine on its own. It it can fire when it gets enough what they call proximal input from those ones near the cell fire. But it can get ready to fire from dozens to hundreds of patterns that it recognizes from the other guys. And the advantage of this to the neuron is that when it actually does produce a spike in action potential, it does so slightly sooner than it would have otherwise.
And so what good is slightly soon? Well, the slightly sooner part is it does it all the neurons in the of throwing a wrench in the brain are surrounded by these inhibitory neurons and they are very fast. The train runs in basketball.
And if I get my spike out a little bit sooner than someone else, I inhibit all my neighbors around me.
Right. And what you end up with is a different representation. You end up with a reputation that matches your prediction. it is a it is a partial representation, meaning a are interactive, but it is much more specific. And so we showed how networks of these neurons can do very sophisticated temporal prediction, basically. So so this summarizes real neurons in the brain are time-based prediction engines. And and they and there is no concept that this is all in artificial call point neurons.
I do not think you can mail the brain without them. I do not know. You can build intelligence about because it is the it is where a large part of the time comes from. it is these are predictive models. And the time is is there is a prior and a prediction and an action, and it is inherent through every neuron in the neocortex.
So so I would say that point neurons sort of model a piece of that and not very well at that either. But like, for example, synapses are very unreliable and you cannot assign any precision to them. So even one digit a position is not possible. So the way real neurons work is they do not add these they do not change these weights accurately like artificial neural networks do. They basically form new synapses. And so what you are trying to always do is, is detect the presence of some 10 to 20 active synapses at the same time as opposed.
And they are almost binary. it is like because you can not really represent anything much finer than that. So these are the kind of and I think that is actually another essential component, because the brain works on sparse patterns and all that all that mechanism is based on past patterns. And I do not actually think you could build real brains or our machine intelligence without incorporating some of those ideas.
it is hard to even think about the complexity that emerges from the fact that the timing of the firing matters in the brain, the fact that you form new new synapses and I mean everything you just mentioned in the past, you can trust me if you spend time on it, you can get your mind around it.
it is not like it is no longer a mystery to me.
No, but Busari is a function in a mathematical way. it is can you get it? Start getting an intuition about what gets it excited or not.
it is not as easy as there are many other types of neural networks are that are more amenable to pure analysis, you know, especially very simple networks. You know, oh, I have four neurons and they are doing this.
Can we describe the mathematically what they are doing type of thing, even the complexity of neural networks today? it is sort of a mystery that can not really describe the whole system. And so it is different.
My colleague, Sebti Amad, he did a nice paper on this.
You can get all the stuff on our website if you are interested. I am talking about sort of the mathematical properties of Spanish representations. And so we can not what we can do is we can do it mathematically. For example, why ten to 20 synapses to recognize a pattern is the correct number, is the right number you would want to use. And by the way, that matches biology. We can show mathematically some of these. that is about the show, why the brain is so robust to noise and error and fallout and so on, we can show that mathematically as well as empirically in simulations.
But the system can not be analyzed completely.
Any complex system can. And so that is out of the realm. But there is there are mathematical benefits and intuitions that can be derived from mathematics. And we try to do that as well. Most most of our papers have a section about that.
So I think it is refreshing and useful for me to be talking to you about individual networks, because your intuition basically says that we can not achieve anything like intelligence with artificial neon that works well, not in their current form.
Neither can do it in the ultimate form. Sure.
So let me dig into it and see what your thoughts are there. A little bit. So I am not sure if you read this little blog post called Bitter Lesson by Richard Sutton recent recently. he is a reinforcement learning pioneer. I am not sure if you are familiar with him. His basic idea is that all the stuff we have done in A.I. in the past 70 years, he is one of the old school.
that is the biggest lesson learned is that all the tricky things we have done, do not they benefit in the short term? But in the long term, what wins out is a simple general method that just relies on Moore's Law and on computation getting faster and faster.
So that is what he is saying. This is what has worked up to now. This what has worked up to now that if you are trying to build the system, if we are talking about he is not concerned about intelligence. he is concerned about a system that works in terms of making predictions and applied narrow problems.
Right.
that is what the discussion is about that, that you just try to go as general as possible and wait years or decades for the competition to make it.
Actually, do you think that is a criticism or is he saying this is a prescription of what we ought to be doing? Well, it is very difficult.
he is saying this is what has worked and, yes, a prescription. But it is a difficult prescription because it says all the fun things you guys are trying to do.
We are trying to do. he is part of the community is saying it is only going to be short term gains.
So this all leads up to a question, I guess, on artificial neural networks and maybe our own biological neural networks is do you think if we just scale things up significantly, so take these dumb artificial neurons?
The point is, I like that term.
If we just have a lot more of them. Do you think some of the elements that we see in the brain may start emerging? No, I do not think so.
We can do bigger problems. And of the same type. I mean, it is been pointed out by many people that today is convolutional. Neural networks are not really much different than the ones we had quite a while ago. We just they are bigger and train more and we have more data and so on. Uh, but I do not think you can get to the kind of things I know the brain can do and that we think about as intelligence by just scaling it up.
So that may it is a good description of what is happened in the past, what is happened recently with the emergence of artificial neural networks.
It may be a good prescription for what is going to happen in the short term, but I do not think that is the path. I said that earlier. there is an alternate path I should mention to you, by the way, that we have made sufficient progress on our the whole cortical theory in the last few years, that last year we decided to start actively pursuing. How do we get these ideas embedded into machine learning?
Well, that is again being led by my colleague Sleepytime on. And he is more of a machine learning guy. I am more of a neuroscience guy.
So this is now it is just I would not say our focus, but it is now an equal focus here because we we need to proselytise what we have learned and we need to show how it is beneficial to to to the world.
So we are putting we have a plan in place right now. In fact, we just did our first paper on this. I can tell you about that.
But, you know, one of the reasons I want to talk to you is because I am trying to get more people in the machine learning community to say, look, I need to learn about this stuff and maybe we should just think about this a bit more about what we have learned about the brain and what of those teams, no matter what have they done?
Is that useful for us?
Yeah. Yeah. So is there elements of all the the cortical theory that things we have been talking about that may be useful in the short term and the short term? Yes, this is the sorry to interrupt the the open question, is it? It certainly feels from my perspective that in the long term, some of the ideas we have been talking about will be extremely useful. The question is whether in the short term.
Well, this is a always what I would call the entrepreneur's dilemma. So you have this long term vision. we are going to all be driving electric cars or we are all going to have computers or whatever, and and you are at some point in time and you say, I can see that long term vision, I am sure it is going to happen.
How do I get there without killing myself, you know, without going out of business? that is the challenge. that is the dilemma. that is the really difficult thing to do.
So we are facing that right now. So ideally, what you want to do is find some steps along the way. You can get there incrementally. You do not have to, like, throw it all out and start over again. The first thing that we have done is we focus on these misrepresentations. So just just in case you do not know what that means or some of the listeners do not know what that means in the brain.
I have like ten thousand neurons. What you would see is maybe two percent of them active at a time. You do not see 50 percent. You do not think 30 percent. You might see two percent.
And it is always like that for any set of sensory input.
It does not matter if anything does matter, any part of the brain. But which neurons differs? Which neurons are active?
Yeah, it is still going to be let us I take ten thousand neurons that are representing something that is sitting there in a blue block together. it is a teeny little black and around ten thousand. Right. And they are representing a location. they are representing a cop. they are representing the input from my sensors. I do not know. It does not matter.
it is representing something. The way the representations occur. it is always a sparse representation, meaning it is a population to which two hundred cells are active. Tells me what is going on. it is not individual cells are not that important at all. it is the population code that matters. And when you have sparse population codes, then all kinds of beautiful properties come out of them. So the brain uses sparse population codes. And we have we have written and described these benefits in some of our papers.
So they get this tremendous robustness to the systems. Brains are incredibly robust. Neurons are dying all the time and spasming and synapses falling apart all the time. And it keeps working.
So what Sebti and Louise, one of our other engineers, have done, I have shown they are introducing sparseness into convolutional networks and other people are thinking along these lines. But we are going about it in a more principled way, I think.
And we are showing that if you enforce sparseness throughout these convolutional neural networks in both the act, which sort of neurons are active and the connections between them, that you get some very desirable properties. So one of the current hot topics in deep learning right now is these adversarial examples. So, you know, you give me any deep learning network and I can give you a picture that looks perfect and you are going to call it, you know, you are going to see the monkey is, you know, an airplane.
So that is the problem in Darfur.
Just announced some big thing. we are trying to, you know, have some contest for this.
But if you if you enforce past representations here, many of these problems go away. they are much more robust and they are not easy to fool. So we have already shown some of those results just literally in January or February, just like last month.
We did that. And you can I think it is on Baiocco right now or you can read about it.
But so that is like a baby step that is taking something for the brain. We know we know about sparseness. We know why it is important. We know what gives the brain. So let us try to enforce that on.
what is your intuition? Why sparsity leads to robustness? Because it feels like it would be less robust. So why why would you feel the rest of us to you?
So it just feels like if the fewer neurons are involved, the more fragile that represent.
But I did not say there was lots of Funen. I said to say two hundred. that is a lot. Still a lot. Yeah. So here is an intuition for it. This is a bit technical. So for, you know, for engineers or machine learning people, this is easy. But the lesson is maybe not.
If you are trying to classify something, you are trying to divide some very high dimensional space into different pieces. And and you are trying to create some point where you say all these points in this high dimensional space and all these points inside dimensional space would be.
And if you have points that are close to that line, it is not very robust. It works well, all the points you know about. But it is it is not very robust because you can just move a little bit and you have crossed over the line when you have sparse representations. Imagine I pick I have I am going to pick 200 cells active out of out of ten thousand. OK, so I have 200 cells active. Now, let us say I pick randomly another a different representation.
Two hundred. The overlap between those is going to be very small. Just a few. I can pick millions of samples randomly of two hundred neurons and not one of them well over more than just a few. So one way to think about is if I want to fool one of these representations to look like one of those other representations, I can not move just one cell or two cells or three cells of four cells. I have to move one hundred cells.
And that makes them robust in terms of. Of further, so you mentioned sparsity. Well, the next thing, yeah. OK, so we have we picked one. We do not know if it is going to work well yet. So again, we are trying to come up incremental ways to moving from brain theory to adding pieces to machine learning, current machine learning world and one step at a time.
So the next thing we are going to try to do is sort of incorporate some of the ideas of the thousand brains theory that you have many, many models and that are voting. Now, that idea is not new. there is a mixture of models that is been around for a long time.
But the way the brain does is a little different and and the way it votes is different. And the kind of way it represents uncertainty is different. So we are just starting this work, but we are going to try to see if we can sort of incorporate some of the principles of voting or principles of a thousand brain theory, like lots of simple models that talk to each other in a in a very certain way. And can we build more machines and systems that learn faster and and also.
Well, mostly our multimodal and robusta multimodal type of issues.
So one of the challenges there is, you know, the machine learning computer vision community has certain sets of benchmarks, sets of tests based on which they compete. And I would argue, especially from your perspective, that those benchmarks are not that useful for testing the aspects that the brain is good at or intelligent. they are not really testing it. it is a very fine. Yeah, and it is been extremely useful for developing specific mathematical models, but it is not useful in the long term for creating intelligence.
So you think you also have a role in proposing better tests?
Yeah, this is a very you have identified a very serious problem. First of all, the tests that they have or the tests that they want, not the test of the other things that we are trying to do. Right. You know, one of the so on the second thing is sometimes these to be competitive in these tests, you have to have huge datasets and huge computing power. And, you know, and we do not have that here. We do not have as well as other big teams and big companies do.
So there is numerous issues there.
You know, we come out, you know, we are our approach to this is all based on in some sense, you might argue, elegance. we are coming at it from like a theoretical base that we think, oh, my God, this is a clearly elegant this our brains work. This one is. But the machine learning world has gotten in this phase where they think it does not matter, does not matter what you think, as long as you do point one percent better on this benchmark.
that is that is all that matters. And and that is a problem. You know, we have to figure out how to get around that. that is that is a challenge for us. that is that is one of the challenges that we have to deal with.
So I agree you have identified a big issue. it is difficult for those reasons. But, you know, but, you know, part of the reasons I am talking to you here today is I hope I am going to get some machine learning people to say, if you read those papers, those might be some interesting ideas. I am sure I am doing this point one percent improvement stuff, you know?
Well, that is that is why I am here as well, because I think machine learning now as a community is at a place where the next step is needs to be orthogonal to what has received success in the past.
Do you see other leaders saying this, machine learning leaders? You know, Jeff Hinton with his capsule's idea. Many people have gotten say, you know, we are going to hit road. Maybe we should look at the brain, you know, things like that.
So hopefully that thinking like occur organically.
And then then we are in a nice position for people to come and look at our work and say, well, what can we learn from these guys?
Yeah, MIT is launching a billion dollar computing college, the center on this idea. So this idea of what of well, the idea that, you know, the humanities, psychology and neuroscience have to work all together to get to build this.
Yeah. I mean, Stanford just did this human center day, sent it. I am a little disappointed in these initiatives because.
Yeah. You know, they are focusing on sort of the human side of it, and he can very easily slip into how humans interact with intelligent machines, which is nothing wrong with that. But that is not that is orthogonal to what we are trying to do. we are trying to say, like, what is the essence of intelligence? I do not care that I want to build intelligent machines that are not emotional, that do not smile at you, you know, are not trying to tuck you in at night.
Yeah. There is that pattern that you when you talk about understanding the humans is important for understanding intelligence. You start slipping into topics of ethics or. Yeah, like you said, the interactive elements are supposed to know know where to zoom in on the brains. They say what the human brain, the baby, the what the brain does does.
And then we can decide which parts of that we want to recreate in some system. But do you have that theory about what the brain does? what is the point?
You know, just you are going to be wasting time, I think, just to break it down on the artificial network side, maybe you can speak to this on and the biological, you know, the process of learning versus the process of inference. Maybe you can explain to me why is there a difference between, you know, an artificial neural networks, there is a difference between the learning stage and the inference stage. Do you see the brain is something different?
One of the one of the big distinctions that people often say, I do not know how correct it is, is artificial neural networks need a lot of data. they are very inefficient learning. Do you see that as a correct distinction from the the biology of the human brain that the human brain is very efficient? Or is that just something we deceive ourselves?
No, it is efficient. Obviously, we can learn new things almost instantly. And so what elements do you think I can talk about that?
You brought up two issues there. So I talked earlier about the constraints we always feel. Well, one of those constraints is the fact that brains are continually learning. that is not something we said. Oh, we can add that later. that is something that was up front.
Had to be there from the start, made our problems harder. But we showed going back to the 2016 paper on sequenced memory, we showed how that happens, how our brains infer and learn at the same time. And our models do that. they are not two separate phases or two separate sets of time. I think that is a big, big problem in AI, at least for many applications, not for all. So I can talk about that.
There are some that gets detailed. There are some parts of the neocortex in the brain where actually what is going on? Those are those with these cycles. they are like cycles of activity in the brain.
And there is very strong evidence that you are doing more of inference on one part of the phase and more of learning on the other part of the face of the brain can actually sort of separate different populations of cells are going back and forth like this. But in general, I would say that is an important problem. We have all of our networks that we have come up with do both, and they are learning continuous learning networks. And you mentioned Benchmark's earlier. Well, there are no benchmarks about that.
Exactly.
So so we you know, we have to like, you know, we get our little soapbox and hey, by the way, you know, this is important, you know, and here is a mechanism for doing that. But then, you know, but until you can prove it to someone in some commercial system or something a little harder.
So, yeah, one of the things to link on that is in some ways to learn the concept of a coffee cup. You only need this one coffee cup and maybe some time alone in a room with it.
Well, the first thing is I would imagine I reached my hand into a black box and I am reaching I am trying to touch something I do not know, up front if it is something I already know or if it is a new thing. And I have to I am doing both at the same time. I do not say, oh, let us see if it is a new thing. Oh, let us see if it is an old thing. I do not do that as I go. My brain says, oh, it is new or it is not new.
And if it is new, I start learning what it is.
So and by the way, it starts learning from the get go even if we do not recognize it. So they are they are not separate problems. And so that is the thing. Or the other thing you mentioned was the fast learning. So I was just talking about continuous learning. But there is also facilty literally. I can show you this coffee cup and I say here is a new coffee cup because the logo on it, take a look at it. Done. you are done.
You can predict what it is going to look like, you know, in different positions. So I can talk about that, too, in the brain, the way learning occurs. I mentioned this earlier about I mentioned again, the way learning occurs. I imagine I have a section of a dendrite of a neuron and I want to learn I am going to learn something new. I am just it does not matter what it is, I am just going to learn something new. I need to recognize a new pattern.
So what I am going to do, I am going to form new synopsize.
New Synopsize, We got to rewire the brain onto that section of the dendrite once I have done that, everything else that neuron has learned is not affected by it. that is because it is isolated to that small section of the dendrite. they are not all being added together like a point in room. So if I learn something new on this segment here, it does not change any of the learning occur anywhere else in that neuron. So I can add something without affecting previous learning and I can do it quickly.
Now, let us talk we can talk about the quickness, how it is done in real neurons. You might say, well, does not it take time to form synapses? Yes, it can take maybe an hour to form a new synapse. We can form memories quicker than that. And I can explain that out to if you want, but it is getting a bit neuroscience, so that is great.
But is there an understanding of these mechanisms at every level? Yeah. So from the short term memories and the forming well.
So this idea of synaptic genesis, the growth of new synapses, that is well described as well. Understood.
And that is an essential part of learning. That is learning. That is learning. OK, you know, back you know, going back many, many years, people, you know, as what is his name, the psychologist proposed. You have Donald Trump. He proposed that learning was the modification of the strength of a connection between two neurons. People interpreted that as the modification of the strength of a synapse. He did not say that. He just said there is a modification between the effect of one neuron, another.
So synaptic genesis is totally consistent with Donald Pepcid. But anyway, there is these mechanisms, the growth of new sounds. You can go online, you can watch a video of a synapse growing in real time.
it is literally you can see this little thing going, boom, it is pretty impressive.
So those mechanisms are known. Now, there is another thing that we have speculated and we have written about, which is consistent with no neuroscience, but it is less proven.
And this is the idea, how do I form a memory really, really quickly, like instantaneously if it takes an hour to go synapse, that is not instantaneous.
So there there are types of synapses called silent synapses. They look like a synapse, but they do not do anything.
they are just sitting there. it is like actual potential that comes in. It does not release any neurotransmitter.
Some parts of the brain have more of these and others. For example, the hippocampus has a lot of them, which is where we associate most short term memory with.
So what we speculated again in that 2016 paper, we proposed that the way we formed very quick memories, very short term memories or quick memories is that we convert silence synapses, interactive synapses.
it is going it is like seeing a synopsis of 08 in a one way, but the long term memory has to be formed by synaptic genesis.
So you can remember something really quickly by just flipping a bunch of these guys from silent active. it is not like it is not from point one to point one five.
it is like does not do anything to release his transmitter. And if I do that over a bunch of these, I have got a very quick short term memory. So I guess the lesson behind this is that most neural networks today are fully connected. Every neuron connects every other neuron from layer to layer. that is not correct in the brain. We do not want that. We actually do not want that. it is bad. You want a very sparse connectivity so that any neuron connects to some subset of the neurons and the other layer.
And it does so on a on a dendrite by dendrite segment basis. So it is a very isolated out type of thing. And and that then learning is not adjusting all these ways, but learning is just saying, OK, connect to these 10 cells here right now.
And that that process with artificial neural networks, it is a very simple process of back propagation that adjusts the way the process of synaptic genesis is not the synaptic genesis. it is even easier.
it is even easier. it is even easier that propagation requires something we really can not happen in brings this back propagation of this error signal that really can not happen.
People are trying to make it happen and brains do not happen to be. This is this is pure happy and learning what not to Genesis pure heavy learning. it is basically saying there is a population of cells over here that are active right now and there is a population cells up here active right now. How do I form connections between those active cells? And it is literally saying this guy became active. This these neurons here became active before this neuron became active. So form connections to those ones.
that is it. there is no propagation of error. Nothing. All the networks we do, all models we have work on, almost completely on heavy learning, but in in on dendritic segments and multiple synopsize at the same time, the notes have turned the question that you already answered, and maybe you can answer it again.
If you look at the history of artificial intelligence, where do you think we stand?
How far are we from solving intelligence? You said you were very optimistic.
Yeah. Can you elaborate on that? Yeah. You know, it is always the the crazy. And I ask because, you know, no one can predict the future. Absolutely. So I will tell you a story.
I used to I used to run a different neuroscience institute called the Redwood Neuroscience Center. And we would we would hold these symposiums and we get like thirty five scientists from around the world to come together. And I used to ask them all the same question. I would say, well, how long do you think it will be before we understand how the neocortex works? And everyone went around the room and they had introduced the name and they have to answer that question.
So I got the typical answer was 50 to 100 years. Some people would say 500 years. Some people said never.
I said, what are you why? you are a neuroscientist. it is a good pay.
Interesting. So, you know, but it does not work like that. As I mentioned earlier, these are not these are still functions. Things happen. And then, bingo, they happen. You can not predict that. I feel I have already passed a step function. So if I can do my job correctly over the next five years, then meaning I can proselytize these ideas.
I can convince other people that.
Right. We can show that other people are a machine learning. People should pay attention to these ideas, then we are definitely in an under 20 year time frame. If I can do those things.
If I if I am not successful in that and this is the last time anyone talks to me and no one reads our papers and you know, I am wrong or something like that, then then I do not know.
But it is not 50 years. it is it you know, it will it will you know, the same thing about electric cars.
How quickly are they going to populate the world? let us probably takes about a 20 year span. it will be something like that. But I think if I can do what I said, we are starting it.
And of course, there could be other that functions. It could be everybody gives up on your ideas for 20 years and then all of a sudden somebody picks it up again. Wait, that guy was on to something. Yeah. So that would be a that would be a failure on my part. Right. You know. Yeah. Think about Charles Babbage. You know, Charles Babbage invented the computer back in the 18th century, hundreds.
And everyone forgot about it until, you know, 100 hundred years later, this guy for a long time ago, you know, but he was ahead of his time.
Yeah. I do not think, you know, like as I said, I recognize this is part of any entrepreneur's challenge. I use entrepreneur broadly in this case. I am not meaning like I am building a business, trying to sell something. I mean, I I am trying to sell ideas.
And this is the challenge as to how you get people to pay attention to you. How do you get them to give you positive or negative feedback, how you get to people act differently based on your ideas. So, you know, we will see how what we do on them.
So, you know that there is a lot of hype behind artificial intelligence currently. Do you as as you look to spread the ideas that are of neocortical theory, the things you are working on, do you think there is some possibility will hit? And I went to it once again.
Yeah, it is certainly a possibility. No, about worry about. Yeah, well, I guess.
Do I worry about it. I have not decided yet if that is good or bad for my mission.
that is true. that is very true because it is almost like you need the the winter to refresh the palate. Yeah.
it is, it is like I want here is what you want to have it if you want like to extend it. Everyone is so thrilled about the current state of machine learning and I and they do not imagine they need anything else that makes my job harder. If if everything crashed completely and every student left the field and there was no money for anybody to do anything, and it became an embarrassment to talk about machine intelligence and A.I., that would not be good for us either.
You want you want sort of the soft landing approach, right? You want enough people in the senior people in AI and machine learning and say, you know, we need other approaches, we really need other approaches. Damn, we need other approaches. Maybe we should look to the brain. OK, let us look at the brain. who is got some brain ideas. OK, let us let us start a little project on the side here trying to do brain idea related stuff.
that is the ideal outcome we would want.
So I do not want a total winter and yet I do not want it to be sunny all the time either.
So what do you think it takes to build a system with human level intelligence where once demonstrated you would be very impressed? So does it have to have a body? Does it have to have the the the C word we use before consciousness as an entirety, as in a holistic sense?
First of all, I do not think the goal is to create a machine that is human level intelligence. I think it is a false goal. It back to touring. I think it was a false statement. We want to understand what intelligence is and then we can build intelligent machines of all different scales, all different capabilities. You know, a dog is intelligent. I do not think I would be pretty good to have a dog, you know, but what about something that do not look like an animal at all in different spaces?
So my thinking about this is that we want to define what intelligent does agree upon, what makes an intelligent system. We can then say, OK, we are now going to build systems that work on those prints. Or some subset of them, and we can apply them to all different types of problems and the the kind the idea, it is like computing. We do not ask if I take a little, you know, little one chip computer, I do not say, well, that is not a computer because it is not as powerful as this, you know, big server over here.
No, no. Because we know that what the principles of computing are and I can apply those principles to small problems were a big problem in same intelligence needs to get there. We have to say these are the principles. I can make a small one, a big one. I can make them distributed. I can put them on different sensors. They do not have to be human like at all. Now, you did bring up a very interesting question about embodiment.
Does it have to have a body? It has to have some concept of movement. It has to be able to move through these reference frames I talked about earlier, whether it is physically moving like I need.
If I am going to have an AI that understands coffee cups, it is going to have to pick up the coffee cup and touch it and look at it with it, with its eyes and hands or something equivalent to that. If I have a mathematical A.I., maybe it needs to move through mathematical spaces. I could have a virtual A.I. that lives in the Internet and its its movements are traversing links and digging into files. But it is got a location that it is traveling through some space.
You can not have an eye that just take some flash thing. You know, we call it flash in France. here is a pattern done. No, it is movement, moving pattern movement, pattern movement, attention, digging, building, building structure, just figuring out the model of the world. So some sort of embodiment embodiment, whether it is physical or not, has to be part of it.
So self-awareness in the way to be able to answer where am I to bring up a different topic? Self awareness, not the very narrow definition.
So meaning knowing a sense of self enough to know where am I in this space?
Yeah, basically the system, the system needs to know its location. Well, each component of the system needs to know where it is in the world at that point in time.
So self-awareness and consciousness, do you think one from the perspective of neuroscience and neocortex, these are interesting topics, solvable topics. Do you have any ideas of what why the heck it is that we have a subjective experience at all? Yeah, I have a lot of fun. Is it useful or is it just a side effect?
it is interesting to think about it. I do not think it is useful as a means to figure out how to build intelligent machines.
it is it is something that systems do and we can talk about what it is that are like, well, I built the system like this, then it would be self-aware or in if I build it like this, it would not be self aware.
So that is a choice I can have.
it is not like, oh my God, there is no way. No, I can not. I heard an interview recently with this philosopher from Yale. I can not remember his name. I apologize for that.
But he was talking about, well, if these computers are self aware, then it would be a crime to unplug them. And I am like, oh, come on. I thought, you know, I did not play myself. Every night I go to sleep. What is that, a crime? You know, I put myself in again in the morning. I am. I am so.
You know, people get kind of bent out of shape about this. I have very definite, very detailed understanding or opinions about what it means to be conscious and what it means to be self aware. I do not think it is that interesting a problem. You talked to McChrystal. You know, he thinks that is the only problem.
I did not actually listen to your interview with him, but I know him and I know that he also thinks intelligence and consciousness are disjoint. So, I mean, it is not that one or the other. So he is I just agree with that. I just totally agree with that.
So where is your thoughts of where does it emerge from? Because it is so then we have to break it down to the two parts. OK, because consciousness is not one thing that is part of the problem. That term is it means different things to different people and there is different components of it. There is a concept of self awareness that it can be very easily explained. You have a model of your own body, the neocortex, models, things in the world, and it also models your own body and and then it has a memory.
It can remember what you have done. OK, so it can remember what you did this morning and remember what you had for breakfast and so on. And so I can say to you, OK, were you conscious this morning when you had your bagel and you say, yes, I was conscious. Now what if I could take your brain and revert all the synapses back to the state they were this morning? And then I said to you next, were you conscious when you ate the big lunch?
No, I was not conscious. here is a video of eating the bagel and saying I was not there. I know that is not possible because I was I must have been unconscious at that time. So we can just make this one to one correlation between memory of your body's trajectory through the world over some period of time, a memory and the ability to recall that memory is what you would call consciousness.
I was conscious of that self awareness and any system that can recall memories, what it is done recently and bring that back and invoke it again would say, yeah, I am aware. I remember what I did. All right. I got that is an easy one. Although some people think that is a hard one. The more challenging part of consciousness is this is one that sometimes used by the word of qualia, which is, you know, why does an object seem red or what is pain and why does pain feel like something?
Why do I feel redness or what do I feel pain just in a way. And then I could say, well, why? The sight seems different than hearing. You know, it is the same problem. it is really these are all these neurons. And so how is it that we are just looking at you feel different than you know, I am hearing you.
It feels different. But this is neurons in my head.
they are all doing the same thing. So that is interesting question. The best treatise I have read about this is by a guy named O'Reagan or Wiggan. He wrote a book called Why Red does not Sound Like a Bell.
it is a little it is not a trade book.
it is a read. But it and and it is an interesting question. Think something like color color really does not exist in the world. it is not a property of the world. Probably the world that exists is like frequency. And that gets turned into we have certain cells in the retina that respond to different frequencies, different than others. And so when they enter the brain, you have a bunch of axons that are firing at different rates. And from that we perceive color.
There is no color in the brain. I mean, there is there is no color coming in of those synapses. it is just a correlation between something some some axons and some property of frequency. And that is not even color itself. Frequency does not have a color. it is just a it is just what it is.
So then the question is, why does it even appear to have a color at all?
Just as you are describing it? there is seems to be a connection to those ideas of reference frames. I mean, it just feels like consciousness, having the subject, assigning the feeling of red to the actual color or to the wavelength. it is useful for intelligence.
I think that is a good way of putting it. it is useful as a predictive mechanism, more useful as a generalization. I did. it is a way of grouping things together to say it is useful to have a model like this. Yes.
Think about the there is a well known syndrome that people who have lost a limb experience called phantom limbs. And what they claim is they can have their arm is removed, but they feel their arm that not only feel that they know it is there. Yeah, they it is there. I can I know it is there. Just swear to you that it is there and then they can feel pain in the arm and in their finger and if they move there, they move their non-existent arm behind your back, then they feel the pain behind your back.
So this whole idea that your arm exists is a model of your brain.
It may or may not really exist. And just like but it is useful to have a model of something that sort of correlates to things in the world so you can make predictions about what would happen when those things occur. it is a little bit of a fuzzy, but I think you are getting right towards the answer there. it is it is useful for the model of to to express things, certain ways that we can then map them into these reference frames and make predictions about them.
I need to spend more time on this topic. It does not bother me.
Do you really need to spend more time? Yeah, it does feel special that we have subjective experience, but I am yet to know why.
I am just I am just personally curious. it is not necessary for the word. we are doing here. I do not think I need to solve that problem to build intelligent machines at all, not at all. But there is sort of the silly notion that you describe briefly that does not seem so silly to us humans, is, you know, if you are successful building intelligent machines, it feels wrong to then turn them off because if you are able to build a lot of them, it feels wrong to then be able to, you know, to turn off the well.
Why we just let us break that down a bit as humans. Why do we fear death? there is there is two reasons we fear death. Well, first of all, I will say, when you are debt does not matter all, you are dying. So why do we fear death? We fear death for two reasons.
One is because we are programmed genetically to fear death. that is a that is a survival and getting the genes thing. And we also are programmed to feel sad when people we know die.
We do not feel sad for someone we do not know dies. Is people dying right now? I am saying I am for the better man because I do not know them.
But if I knew them, I would feel really bad. So again, these are all brain genetically imbedded things that we fear death outside of those those uncomfortable feelings, there is nothing else to worry about.
Wait, wait. Hold on a second. Do you know the denial of death by Becker? You know, there is a thought that death is.
You know, our whole conception of our world model kind of assumes immortality and then death is this terror that underlies it all.
So like, well, some people's world, not mine, but OK, so what would Becker would say is that you are just living an illusion. you have construct an illusion for yourself because it is such a terrible terror.
The fact that the illusion that death is about you still not coming to grips with the illusion of what that death is going to happen.
Oh, it is not going to happen.
you are you are actually operating. You have not even though you said you have accepted it, you have not really accepted. And she dies, as you say. So it sounds like it sounds like you disagree with that notion.
I mean, I totally I, I like that every night I go to bed, it is like dying the little deaths.
And if I did not wake up, it would not matter to me. Only if I knew that was going to happen. Would it be bothersome if I did not know? How about how would I know? No. Then I would worry about my wife. So imagine imagine I was a loner and I lived in Alaska and I lived out there and there was no animals. Nobody knew I existed. I was just eating these routes all the time and nobody knew was there.
And one day I did not wake up. What pain in the world would there exist?
Well, so most people think about this problem would say that you are just deeply enlightened or are completely delusional.
But I would say I would say that is very enlightened way to see the world, is that that is the rational one. The rational. that is right.
But the fact is, we do not I mean, we really do not have an understanding of why the heck it is we are born and why we die and what happens afterwards.
Maybe there is not a reason. Maybe there is. So I am interested in those big problems, too. Right. You know, you you interviewed Max Tegmark. You know, there is people like that, right?
I mean, those big problems as well. And in fact, when I was young, I made a list of the biggest problems I could think of. First, why is anything exist? Why did we have the laws of physics that we have? Third, is life inevitable and why is that here? Fourth, is intelligence inevitable? And why is it here?
I stop there because I figured if you can make a truly intelligent system, will that be the quickest way to answer the first three questions?
I am serious. Yeah.
And and so I said my mission you asked me really my first mission is to understand the brain, but I felt that is the shortest way to get the true machine intelligence. And I want to get the true machine intelligence, because even if it does not occur in my lifetime, other people will benefit from it because I think it will come in my lifetime. But, you know, twenty years, you never know.
And but that would be the quickest way for us to you know, we can make super mathematicians, we can make super space explorers. We can make super physicists brains that do these things and they can run experiments that we can not run.
We do not have the ability to manipulate things and so on. But we can build intelligent machines that do all those things.
And with the ultimate goal of finding out the answers to the other questions, let me ask you the depressing and difficult question, which is once we achieve that goal of creating it.
No, of understanding intelligence, do you think we would be happier, more fulfilled as a species to understanding intelligence or understanding the answers to the big questions, understanding intelligence?
Oh, totally. Totally.
It would be far more fun place to live, you think? Oh, yeah, why not? I mean, you know, just put aside this, you know, Terminator nonsense.
And and and just think about you can think about we can talk about the risk if you want, but let us do so.
let us talk about I think the world would be far better knowing things we always better than know things. Do you think it is better, is it a better place to live in that? I know that our planet is one of many in the solar system and this is one of many of the galaxies. I think it is a more I dreamt I used. I sometimes think like what it would be like to live. Three hundred years ago I would be looking at the sky.
I can not understand anything. Oh my God. I would be like going to bed every night going, what is going on here?
Well, I mean, in some sense I agree with you, but I am not exactly sure. I so I am also a scientist. So I have I share your views, but I am not we are like rolling down the hill together of what is down the hill.
I feel for climbing a hill. Whatever it is, we are getting closer to enlightenment.
And whatever we are climbing, we are getting pulled up a hill. we are so polarized it is. we are pulling ourselves up the hill by our curiosity.
Yeah, we are doing the same thing with the rock. Yeah. But OK, our happiness aside, do you have concerns about you know, you talk about Sam Harris, Elon Musk of existential threats of intelligence?
No, I am not worried about existential threats at all. There are there are some things we really do. No need to worry about even today, they things we have to worry about, we have to worry about privacy and about how it impacts false beliefs in the world. And we have real problems that and things to worry about with today's A.I. and that will continue as we create more intelligent systems. there is no question, you know, the whole issue about, you know, making intelligent armament and weapons is something that really we have to think about carefully.
I do not think of those existential threats. I think those are the kind of threats we always face and we will have to face them here and and how to deal with them the way we can.
We could talk about what people think are the existential threats. But when I hear people talking about them, they all sound hollow to me. they are based on ideas. they are based on people who really have no idea what intelligence is. And and if they knew what intelligence was, they would not say those things. So those are not experts in the field, you know, so so there is two right there.
So one is like super intelligence. So a system that becomes far, far superior in reasoning ability than us humans. How is that an existential threat then?
So there is a lot of ways in which it could be one way is us humans are actually irrational, inefficient and get in the way of. Of not happiness, but whatever the objective function is of maximizing that objective function, superintelligent, paperclip problem and things like that, but so the typical problem. But with the superintelligent. Yeah.
So we already faced a threat in some sense. The cold bacteria, these are organisms in the world that would like to turn everything into bacteria and they are constantly morphing, they are constantly changing to evade our protections.
And in the past, they have killed huge swaths of populations of humans on this planet.
So if you want to worry about something that is going to multiply endlessly, we have it. And I am far more worried in that regard. I am far more worried that some scientists in the laboratory will create a super virus or super bacteria that we cannot control. That is a more existential threat.
Putting putting an intelligent thing on top of it actually seems to make it less existential to me. it is like it limits its power, its limits where it can go. It limits the number of things they can do. In many ways, a bacteria is something you can not you can not even see.
So that is only one of those problems.
Yes, exactly. So the other one, just in your intuition about intelligence, when you think about intelligence as humans, do you think of that as something? If you look at intelligence on the spectrum from zero to us humans, you think you can scale that to something far superior to all the mechanisms?
Let me I want to make another point here before I get there.
Intelligence is the neocortex. It is not the entire brain. If the goal is not to make a human, the goal is not to make an emotional system. The goal is not to make a system that wants to have sex and reproduce. Why would I build that? If I want to have a system that wants to reproduce enough sex, make bacteria, make computer viruses, those are bad things. do not do that. Those are really bad. do not do those things.
Regulate those. But if I just say I want an intelligence system, why does it have to have any human like emotions? Why could why does he even care if it lives? Why does it even care if it has food? It does not care about those things. it is just, you know, it is just in a trance thinking about mathematics or it is out there just trying to build the space for it on Mars.
it is a that is a choice we make. do not make human like things, do not make replicating things, do not make things which have emotions. Just stick to the neocortex.
So that is that is a view that I share. But not everybody shares in the sense that you have faith and optimism about us as engineers of systems, humans as builders of systems to to to not put in. Not so.
But this is why I mentioned the bacteria one, because you might say, well, some person is going to do that. Well, some person today could create a bacteria that is resistant to all the known antibacterial agents.
So we already have that threat. We already know this is going on. it is not a new threat. So just accept that and then we have to deal with it, right? Yeah. So my point has nothing to do with intelligence or intelligence is a separate component that you might apply to a system that wants to reproduce and do stupid things. Yeah, let us not do that.
And in fact, it is a mystery why people have not done that yet. My my dad is a physicist, believes that the reason he says, for example, nuclear weapons have not proliferated amongst evil people. So one is one belief that I share is that there is not that many evil people in the world that would that that would use, whether it is bacteria or nuclear weapons or maybe the future A.I. systems to do bad. So the faction small. And the second is that it is actually really hard technically.
Yeah. So the the intersection between evil and competent is small in terms, and that is the way to really annihilate humanity.
you would have to have, you know, sort of the the nuclear winter phenomena, which is not one person shooting or even ten bombs. Yeah. you would have to have some automated system that detonates a million bombs or whatever. Many thousands.
We have the extreme evil combined with extreme competence.
And just like some stupid system that would automatically, you know, Dr. Strangelove type of thing, you know what I mean?
Look, we could have some nuclear bomb go off in some major city in the world. I think that is actually quite likely even in my lifetime.
I do not think that is like a thing and it will be a tragedy, but it will not be an existential threat. And it is the same as, you know, the virus of nineteen, seventeen, whatever it was, you know, the influenza, these bad things can happen and the plague and so on.
We can not always prevent and we always to always try, but we can not. But they are not existential threats until we combine all those crazy things together in one form.
So on the on the spectrum of intelligence from zero to human, do you have a sense of whether it is possible to create. Several orders of magnitude or at least double that of human intelligence on your.
I think it is the wrong thing to say. Double the intelligence. Break it down into different components. Can I make something that is a million times faster than a human brain? Yes, I can do that. Could I make something that is has a lot more storage than the human brain? Yes, I could do that. More and more copies. Can I make something that attaches to different sensors than human brain? Yes, I can do that. Could I make something that is distributed?
So these we talked earlier about the importance of neocortex voting. They do not have to be co-located. Like, you know, they could be all around the place. I could do that to. Those are the levers I have, but is it more intelligent, what depends what I train and on what is it doing? So here is the thing.
So let us say larger neocortex and or whatever size that allows for higher and higher hierarchies to form.
we are talking about brains. And I could I have something as a super physicist or a super mathematician? Yes.
And the question is, once you have a super physicist, will they be able to understand something? Just sense that it will be audism like us compared to what we ever understand it?
Yeah. Most people cannot understand. General relativity. it is a really hard thing to get. I mean, you are painting a fuzzy picture, stretchy space, you know. Yeah, but the field equations to do that and the deep intuitions are really, really hard.
And I have tried I am unable to do it like these to get you know, these are to get special relativity, General.
that is it, man. that is too much. And so we already live with this to some extent. The vast majority of people can not understand actually what the vast majority of the people actually know.
we are just either we do not have the effort to or we can not do it on time or just not smart enough, whatever. So but we have ways of communicating.
Einstein has spoken in a way that I can understand. he is given me analogies that are useful. I can use those analogies from my own work and think about, you know, concepts that are similar. it is not stupid. it is not like he is existing.
Some other plane has no connection to with my plane in the world here. So that will occur. It already has occurred. that is my point that this story is it already has occurred. We live it every day. One could argue that with we create machine intelligence that think a million times faster than us that it will be so far we can not make the connections.
But, you know, at the moment, everything that seems really, really hard to figure out in the world when you actually figure it out is not that hard enough. We can almost everyone can understand the multiverse, as almost everyone can understand quantum physics. Almost no one can understand these basic things, even though hardly any people could figure those things out.
Yeah, but really understand.
So only a few people really do understand. You need to only understand the the projections, the sprinkles of the useful.
And so that was my example of Einstein. Right. His general theory of relativity is one thing that very, very, very few people can get. And what have we just said? Those other few people are also artificial intelligences.
How bad is that? In some sense they are right.
you are right. They already mean Einstein was not a really normal person. He had a lot of where the quirks. And so the other people who work with him. So, you know, maybe they already were sort of this astral plane of intelligence that we live with it already. it is not a problem. it is still useful.
And, you know, so do you think we are the only intelligent life out there in the universe?
I would say that intelligent life has and will exist elsewhere in the universe. I will say that there is a question about contemporaneous intelligent life, which is hard to even answer when we think about relativity and the nature of spacetime. can not say what exactly is this time some place else in the world.
But I think it is it is you know, I do worry a lot about the the filter idea, which is that perhaps intelligent species do not last very long. And so we have not been around very long. And as a technological species, we have been around for almost nothing, you know, what, 200 years, something like that. And we do not have any data, a good data point on whether it is likely that we will survive or not. So do I think that there have been intelligent life elsewhere in the universe?
Almost certain, of course, in the past. In the future? Yes. Does it survive for a long time? I do not know. This is another reason I am excited about our work is our work meaning that general world of I.
I think we can build intelligent machines that outlast us. And, you know, they do not have to be tied to Earth. They do not have to. You know, I am not saying that recreating, you know, aliens.
I am just saying if I asked myself, this might be a good point to end on here.
If I ask myself, you know, what is special about our species, we are not particularly interesting physically. We are not we do not fly. we are not good swimmers. we are not very fast and not very strong.
You know, it is our brain. it is the only thing. And we are the only species on this planet that is built the model of the world that extends beyond what we can actually sense. we are the only people who know about the far side of the moon and the other universes and I mean other galaxies and other stars and and about what happens in the atom. there is no that knowledge does not exist anywhere else. Only in our heads. Cats do not do it. Dogs and monkeys do not do it.
Just that is what we have created that is unique. Not our genes. it is knowledge. And if I ask me what is the legacy of humanity? What, what what shall our legacy be? It should be knowledge. We should preserve our knowledge in a way that it can exist beyond us. And I think the best way of doing that, in fact, you have to do it, is to have to go along with intelligent machines to understand that knowledge.
that is a very broad idea. But we should be thinking, I call it a state planning for humanity. We should be thinking about what we want to leave behind when as a species, we are no longer here.
And that'll happen sometime sooner or later it is going to happen. And understanding intelligence and creating intelligence gives us a better chance to prolong it does give us a better chance to prolong life.
Yes, it gives us the chance to live on other planets. But even beyond that, I mean, our solar system will disappear one day, just give enough time.
So I do not know. I doubt we will ever be able to travel to other things, but we could tell the stars, but we could send intelligent machines to do that.
So you have you have an optimistic, a hopeful view of our knowledge of the echoes of human civilization living through the intelligent systems we create. Oh, totally.
Well, I think intelligent systems are created in some sense the the vessel for bringing beyond Earth or making them last beyond humans themselves.
So how do you feel about that, that they will not be human, quote unquote?
OK, it is not human. What is human? Our species are changing all the time. Yeah, human today is not the same as humans just 50 years ago. it is what is human. Do we care about our genetics? Why is that important? As I point out, Arjay, next to no more interesting than a bacterium's genetics is no more interesting than, you know, monkeys, genetics.
What we have, what is unique and what is valuable is our knowledge of what we have learned about the world. And that is the rare thing. that is the thing we want to preserve its kids better genes, the knowledge, the knowledge.
that is a really good place. And thank you so much for talking to us. it is fun.
