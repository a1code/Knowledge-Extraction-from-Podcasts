The following is a conversation with Peter Norvig, he is the director of research at Google and the co-author with Stuart Russell of the book Artificial Intelligence, A Modern Approach that educated and inspired a whole generation of researchers, including myself, to get into the field of artificial intelligence. This is the Artificial Intelligence podcast. If you enjoy it, subscribe on YouTube, give it five stars and iTunes support on Patrón or simply connect with me on Twitter. Allex Friedman spelled F.R. Idi Amin.
And now here is my conversation with Peter Norvig.
Most researchers in the aid community, including myself, own all three editions red, green and blue of the artificial intelligence and modern approach. The field defining textbook book made people aware that you wrote with Stuart Russell. How is the book changed and how have you changed in relation to it? From the first edition to the second to the third and now fourth edition as you work on it?
Yeah, so it is been a lot of years, a lot of changes. One of the things changing from the first to maybe the second or third was just the rise of computing power. Right. So I think in the in the first edition we said here is predicate logic. But that only goes so far because pretty soon you have millions of short little pedicured expressions and they could not possibly fit in memory. So we are going to use first order logic that is more concise.
And then we quickly realized, oh, predicate logic is pretty nice because there are really Farsad solvers and other things, and look, there is only millions of expressions and that fits easily into memory or maybe even billions fit into memory now. So that was a change of the type of technology we needed just because the hardware expanded even to the second additional resource constraints from Lucene significantly second down. And that was not really to thousands. Second edition. Right. So in ninety five was a first and then two thousand twenty one or so.
And then moving on from there, I think we are, we are starting to see that again with the use and then more specific type of machinery like the DESPUES and you are seeing custom ASICs and so on for deep learning. So we are seeing another advance in terms of the hardware. Then I think another thing that we especially notice this time around is in all three of the first editions, we kind of said, well, we are going to find Aiyaz maximizing expected utility and you tell me your utility function.
And now we have got 27 chapters where the cool techniques for how to optimize that. I think in this edition, we are saying more, you know what, maybe that optimization part is the easy part and the hard part is deciding what is my utility function, what do I want? And if I am a collection of agents or society, what do we want as a whole?
So you touch that topic in this edition, you get a little bit more into utility. Yeah, that is really interesting. On a technical level, we are almost pushing the philosophical I guess it is philosophical, right? So we have always had a philosophy chapter, which I was glad that we were supporting.
And now it is less kind of the, you know, Chinese room type argument and more of these ethical and societal type issues. So we get into the issues of fairness and bias and and just the issue of aggregating utilities.
So how do you encode human values into a utility function? Is there something that you can do purely through data and a learned way, or is there some systematic? Obviously, there is no good answers yet. there is just beginnings to this, to even opening the.
So there is no one answer. Yes, there are techniques to try to learn that. So we talk about inverse reinforcement learning. Right. So reinforcement learning, you take some actions, you get some rewards and you figure out what actions you should take, an inverse reinforcement learning. You observe somebody taking actions and you figure out well, that this must be what they were trying to do. If they did this action, it must be because they wanted.
Of course, there is restrictions to that, right? So lots of people take actions that are self destructive, whether they are suboptimal in certain ways. So you do not want to learn that. You want to somehow learn the the perfect actions rather than the ones they actually take. So. So that is a challenge for that field. Then another big part of it is just kind of theoretical of saying, what can we accomplish? And so you look at like this this work on the programs to predict recidivism and decide, you know, who should get parole or who should get bail or whatever, and how are you going to evaluate that?
And one of the big issues is fairness across protected classes, protected classes being things like sex and race and so on. And so two things you want is you want to say, well, if I get a score of, say, six out of ten, then I want that to mean the same, whether no matter what race I am on. Yes, right. So I want to have a 60 percent chance of reoccurring regardless. And the makers of the one of the makers of a commercial program to do that.
that is what we are trying to optimize. And look, we achieve that. we have we have reached that kind of balance. And then on the other side, you also want to say, well, if it makes mistakes, I want that to affect both sides of the protected class equally. And it turns out they do not do that right? So they are they are twice as likely to make a mistake that would harm a black person over a white person. So that seems unfair.
So you would like to say, well, I want to achieve both those goals. And then it turns out you do the analysis and it is theoretically impossible to achieve those goals. So you have to trade them all one against the other. So that analysis is really helpful to know what you can aim for and how much you can get. You can not have everything, but the analysis certainly can not tell you where should we make that trade off point.
But nevertheless, then we can, as humans deliberate where that trade off should be. At least we now we are arguing in an informed way.
we are not asking for something impossible. we are saying here is where we are and here is what we aim for. And this strategy is better than that strategy. So that is, I would argue, is a really powerful and really important first step. But it is a doable one, sort of removing undesirable degrees of bias in in systems in terms of protected classes. And there is something I listen to your commencement speech or there is some fuzzier things like you mentioned, Angry Birds, you would not do want to create systems that feed the dopamine enjoyment that feed that optimize for you returning to the system, enjoying the moment of playing the game, of getting likes or whatever this kind of thing or some kind of long term improvement.
Right.
Are you even thinking about that, that that is really going to solve Galeria?
I think that is a really important issue to start really thinking about that. I do not think about that as a as an A.I. issue as much. But as you say, you know, the point is we have built this society in this infrastructure where we say we have a marketplace for attention and we have decided as a society that we like things that are free. And so we want all apps on our phone to be free. And that means they are all competing for your attention.
And then eventually they they make some money, some way through ads or in-game sales or whatever. But they can only win by defeating all the other apps, by stealing your attention and. We built a marketplace where it seems like they are working against you rather than working with you. And I would like to find a way where we can change the playing field. So you feel more like what these things are on my side. Yes, there, let me have some fun in the short term, but they are also helping me in the long term rather than competing against me.
And those are not conflicting objectives. they are just the incentives, the direct current incentives as we try to figure out this whole new world seem to be on the easier part of that, which is feeding the dopamine rush. Right.
But for me, take a quick step back at the beginning of the artificial intelligence, the modern approach book writing. So here you are in the 90s when you first sat down with Stuart to write the book to cover an entire field, which is one of the only books has successfully done that for. Yeah. And actually in a lot of other computer science fields, you know, it is a it is a it is a huge undertaking. So it must have been quite daunting.
What was that process like? Did you envision that you would be trying to cover the entire field?
Was there systematic approach to it that was more step by step? How how did it feel? So I guess it came about, you know, go to lunch with the other faculty at Berkeley and we would say, you know, the field is changing. Seems like the current books are a little bit behind. Nobody's come out with a new book recently. We should do that. And everybody said, yeah, yeah, that is a great thing to do, and we never did anything right.
And then I ended up heading off to industry. I went to Sun Labs. So I thought, well, that is the end of my possible academic publishing career. But I get to do it again at a conference like a year later and said, you know, that book we were always talking about, you guys must be half done with it by now. Right? And he said, well, we keep talking. We never do anything. So I said, well, you know, we should do it.
And I think the reason is that we all felt it was a time where the field was changing. And that was in two ways. So, you know, the good old fashioned A.I. was based primarily on boolean logic, and you had a few tricks to deal with uncertainty, and it was based primarily on knowledge engineering that the way you got something done is you went out and you interviewed an expert and you wrote down by hand everything they knew. And we saw in 95 that the field was changing in in two ways, one, we are moving more towards probability rather than boolean logic, and we are moving more towards machine learning rather than knowledge engineering.
And the other books had not caught that way if they were still in the more in the in the old school, although certainly they had part of that on the way. But we said if we start now completely taking that point of view, we can have a different kind of book. And we were able to put that together.
And it was literally the process, if you remember. Well, did you start writing a chapter? Did you outline. Yeah, I guess I guess we did an outline and then we sort of assigned chapters to each person. At the time I had moved to Boston and Stuart was in Berkeley, so basically we did it over the Internet and, you know, that was not the same as doing it today and, you know, dial up lines and letting in.
And, you know, you you do not let it into one she will and you type cat file name and you hoped it was captured at the other end.
And and certainly you are not sending images and figures back and forth.
Right. Right. I did not work, but, you know, did you anticipate where the field would go from that day from from the Niños?
Did you see the growth into learning based methods, into dangerous methods that followed in the future decades?
We certainly thought that learning was important. I guess we we missed it as being as important as it as it is today. We miss this idea of big data. We missed it. The idea of deep learning had not been invented yet. We could have taken the book from a complete machine learning point of view right from the start. We chose to do it more from a point of view. we are going to first develop the different types of representations and we are going to talk about different types of environments.
Is it fully observable or partially observable and is it deterministic or stochastic and so on. And we made it more complex along those axes rather than focusing on the machine learning axis first. Do you think, you know, there is some sense in which the deep learning craze is extremely successful for a particular set of problems? And, you know, eventually it is going to, in the general case, hit challenges. So in terms of the difference between perception systems and robots that have to act in the world, do you think we are going to return to a modern approach type breadth in addition five and six?
Yeah. And in future decades, do you think deep learning will take its place as a chapter in this bigger is in its bigger view?
Well, I yeah, I think we do not know yet how it is all going to play out. So in the new edition, we have a chapter on deep learning. We got Ian Goodfellow to be the guest author for that chapter. So he said he could condense his whole deep learning book into one chapter. I think he did a great job. We were also encouraged that he you know, we gave him the old neural net chapter and said, have fun with it, modernise that.
And he said, you know, half of that was OK. That certainly there is lots of new things that have been developed, but some of the core was still the same. I think we will gain a better understanding of what you can do there. I think we will need to incorporate all the things we can do with the other technologies, right. So deep learning started out with convolutional networks and very close to perception. And it is since moved to be to be able to do more with actions and some degree of longer term planning.
But we need to do a better job with the representation and reasoning and one shot learning and so on. And I think we do not know yet how that is going to play out.
Do you think looking at the some success, but certainly eventual demise, the partial demise of experts, the symbolic systems in the 80s, do you think there is kernels of wisdom in the work that was done there with logic and reasoning and so on that? Will rise again, in your view, so certainly I think the idea of representation and reasoning is crucial that, you know, sometimes you just do not have enough data about the world to learn Denovo. So you have got to have some idea of representation, whether that was programmed in or told or whatever, and then be able to take steps of reasoning.
I think the problem with the good old fashioned A.I. was one we tried to base everything on these symbols that were atomic. And that is great if you are like trying to define the properties of a triangle, right. Because they have necessary and sufficient conditions. But things in the real world do not. The real world is is messy and does not have sharp edges and dynamic symbols do. So that was a poor match. And then the other aspect was that the reasoning was universal and applied anywhere, which in some sense is good, but it also means there is no guidance as to where to apply.
And so, you know, you started getting these paradoxes like, well, if I have a mountain and I remove one grain of sand, then it is still a mountain. And but if I do that repeatedly, at some point, it is not right. And with logic, you know, there is nothing to stop you from applying things repeatedly, but maybe with something like deep learning and I do not really know what the right name for it is, we could separate out those ideas.
So, one, we could say, you know, a mountain is not just an atomic notion. It it is some sort of something like word embedding that has a more complex representation. Yeah. And secondly, we could somehow learn, yeah, there is this rule that you can remove one grain of sand and you can do that a bunch of times, but you can not do it in near infinite amount of times. But on the other hand, when you are doing induction on the integers, sure.
Then it is fine to do it an infinite number of times. And if we could somehow we have to learn when these strategies are applicable rather than having the strategies be completely neutral and available everywhere.
Any time you use your networks, any time you learn from data, form representation from data and automate away, it is not very explainable as to or it is not introspective to us humans in terms of how this neural network sees the world where why does it succeed so brilliantly and so many in so many cases and failed so miserably in surprising ways and small. So what do you think is this is.
The future there can simply more data, better data, more organized data solve that problem, or is there elements of symbolic systems that need to be brought in which are a little bit more explainable?
Yeah, so I prefer to talk about trust and validation and verification rather than just about explain ability that I think explanations are one tool that you use towards those goals. And I think it is an important issue that we do not want to use these systems unless we trust them and we want to understand where they work and where they do not work and in an explanation can be part of that. Right. So I apply for a loan and I get denied. I want some explanation of why.
And you have in Europe, we have the GDP that says you are required to be able to get that. But on the other hand, the explanation alone is not enough, right? So. You know, we were used to dealing with people and with organizations and corporations and so on, and they can give you an explanation and you have no guarantee that that explanation relates to reality. All right. So the bank tell me, well, you did not get the loan because you did not have enough collateral.
And that may be true or it may be true that they just did not like my religion or or something else. I can not tell from the explanation. And that is that is true whether the decision was made by a computer or by a person. I do want to have the explanations and I want to be able to have a conversation to go back and forth and said, well, you gave this explanation, but what about this and what would have happened if this had happened and what I need to change that.
So I think the conversation is a better way to think about it than just an explanation as a single output. And I think we need testing of various kinds. Right. So in order to know. Was the decision really based on my collateral or was it based on my religion or skin color or whatever? I can not tell if I am only looking at my case, but if I look across all the cases, then I can detect a pattern. All right, so you want to have that kind of capability?
You want to have these adversarial testing, right. So we thought we were doing pretty good at object recognition and images. He said, look, we are at pretty close to human level performance on image and so on. And then you start seeing these adversarial images and you say, wait a minute, that part is nothing like human performance. You can mess with it really easily. You can mess with it really easily. Right. And yeah, you could do that to humans, too.
Right. So in a different way, perhaps humans do not know what color the dress was. Right. And so they are vulnerable to certain attacks that are different than the attacks on the machines. But the you know, the the machines are so striking, they really change the way you think about what we have done. Right. And the way I think about it is I think part of the problem is we are seduced by our low dimensional metaphors, right? Yeah.
So, you know, you like that phrase. You look in in a textbook and you say, OK, now we have mapped out the space. You know, Cat is here and Dog is here. And maybe there is a tiny little spot in the middle where you can not tell the difference. But mostly we have got it all covered. And if you believe that metaphor, then you say, well, we are nearly there. And, you know, there is only going to be a couple of adversarial images.
But I think that is the wrong metaphor. And what you really say is it is not a 2D flat space that we have got mostly covered. it is a million dimension space and cat is this string that goes out in this crazy bath. And if you step a little bit off the path in any direction, you are in nowhere land and you do not know what is going to happen. And so I think that is where we are and now we have got to deal with that. So it was not so much an explanation, but it was an understanding of what the models are and what they are doing.
And now we can start exploring. How do you fix that? Yeah, validating the robustness of the system. So on. But take you back to the this this word trust. Do you think we are a little too hard on our robots in terms of the standards we apply?
So, you know of there is a dance, there is there is there is a dance and non-verbal and verbal communication between humans. You know, if we apply the same kind of standard in terms of humans, you know, we trust each other pretty quickly.
I you know, you and I have not met before. And there is some degree of trust, right. That nothing is going to go crazy wrong. And yet to A.I., when we look at our systems where we seem to approach skepticism, always, always.
And it is like they have to prove through a lot of hard work that they are even worthy of even an inkling of our trust. What do you what do you think about the how how do we break that very close that gap?
I think that is right. I think that is a big issue. Just listening to my friend, Mark Moffett is a naturalist and he says the most amazing thing about humans is that you can walk into a coffee shop or a busy street in a city and there is lots of people around you that you have never met before and you do not kill each other. Yeah, he says chimpanzees cannot do that. Yeah, right. Right. If a chimpanzee is in a situation where here is some that are not from my tribe.
Bad things happen, especially in a coffee shop as delicious food around, you know. Yeah, yeah, but but we humans have figured that out, right. And, you know, for the most part, for the most part, we still go to war. We still do terrible things. But for the most part, we have learned to trust each other and live together. So that is going to be important for our A.I. systems as well. And also, I think in a lot of the emphasis is on A.I., but in many cases it is part of the technology but is not really the main thing.
So a lot of what we have seen is more due to communications technology than A.I. technology. Yeah, you want to make these good decisions. But the reason we are able to have any kind of system at all is we have got the communications that we are collecting the data and so that we can reach lots of people around the world. I think that is a bigger change that we are dealing with.
Speaking of reaching a lot of people around the world and instead of education, you have got one of the many things in terms of education you have done. You taught the intro to Artificial Intelligence Course that signed up one hundred thousand hundred sixty thousand students. there is one of the first successful example of and massive of a massive open online course.
What did you learn from that experience? What do you think is the future of Moakes of education online?
Yeah, it was a great fun doing it, particularly being right at the start. Just because it was exciting and new, but it also meant that we had less competition, right. So one of the things you hear about well, the problem with Moakes is the completion rates are so low. So it must be a failure. And and I got to admit, I am a prime contributor. I probably started 50 different courses, but I have not finished. But I got exactly what I wanted out of them because I had never intended to finish them.
I just wanted to dabble in a little bit either to see the topic matter or just to see the pedagogy of how they do in this class.
So I guess the main thing I learned is when I came in, I thought the challenge was information, saying if I could just take the stuff I want you to know and I am very clear and explain it, well, then my job is done and good things are going to happen. And then in doing the course, I learned, well, yeah, you got to have the information. But really, the motivation is the most important thing that if students do not stick with, it does not matter how good the content is.
And I think being one of the first classes, we were helped by sort of exterior motivation. So we tried to do a good job making it enticing and setting up ways for the community to work with each other to make it more motivated. But really, a lot of it was, hey, this is a new thing and I am really excited to be part of a new thing. And so the students brought their own motivation. And so I think this is great because there is lots of people around the world who have never had this before, you know, would never have the opportunity to go to Stanford and take a class or go to MIT or go to one of the other schools.
But now we can bring that to them. And if they bring their own motivation, they can be successful in a way they could not before.
But that is really just the top tier of people that are ready to do that, the rest of the people just do not see or do not have the motivation and do not see how if they push through and we are able to do it, what advantage that would get them. So I think we got a long way to go before we are able to do that. And I think it will be some of it is based on technology, but more of it is based on the idea of community that you got to actually get people together.
Some of the getting together can be done online, I think some of it really has to be done in person to be able in order to build that type of community and trust.
You know, there is an intentional mechanism that we have developed a short attention span, especially younger people, because sort of shorter and shorter videos online. there is a whatever the the way the brain is developing now.
And with people that have grown up with the Internet, they have quite a short attention span. So and I would say I had the same when I was growing up to probably for different reasons. So I probably would not learn as much as I have if I was not forced to sit in a physical classroom, sort of bored, sometimes falling asleep, but sort of forcing myself through that process, sometimes extremely difficult computer science courses.
what is the difference in your view between in-person? Education experience, which you, first of all yourself had and you have taught, and online education and how do we close that gap if it is even possible? Yeah, so I think there is two issues.
One is whether it is in person or online. So it is sort of the physical location and then the other is kind of the affiliation. Right. So. You stuck with it in part because you were in the classroom and you saw everybody else was suffering in the same way you were, but also because you were enrolled, you had paid tuition, sort of everybody was expecting you to stick with it.
Society, parents. Yeah, because peers. Right. And so those are two separate things. I mean, you could certainly imagine I pay a huge amount of tuition and everybody signed up and says, yes, you are doing this, but then I am in my room and my classmates are in different rooms. Right. We could have things set up that way. So it is not just the online versus offline. I think what is more important is the commitment that you have made.
And certainly it is important to have that kind of informal, you know, I meet people outside of class, we talk together because we are all in it together. I think that is really important, both in keeping your motivation and also that is where some of the most important learning goes on. So you want to have that maybe, you know, especially now we start getting into higher bandwidth and augmented reality and virtual reality. You might be able to get that without being in the same physical place.
Do you think it is possible we will see a course at Stanford, for example, that for students enrolled students is only online in the near future, where literally sort of it is part of the curriculum and there is no. Yeah, so you are starting to see that. I know Georgia Tech has a master's that is done that way. Oftentimes it is sort of they are creeping in in terms of a master's program or sort of further education, considering the constraints of students and so on.
But I mean, literally, is it possible that we, you know, Stanford, MIT, Berkeley, all these places go online only in in the next few decades?
Yeah, probably not, because, you know, they have got a big commitment to a physical campus, right. This there is a momentum that both financially and culturally. Right.
And and then there are certain things that just hard to do virtually. Right. So, you know, we are in a field where if you have your own computer and your own paper and so on, you can do the work anywhere. But if you are in a biology lab or something, you know, you do not have all the right stuff at home. All right. So our field programming, you have also done a lot of you have done a lot of programming yourself.
In 2001, you wrote a great article about programming called Teach Yourself Programming in 10 Years, sort of response to all the books that say teach yourself programming 21 days. So if you were giving advice to someone getting to programming today, this is a few years since you have written that article. what is the best way to undertake that journey? I think there is lots of different ways, and I think programming means more things now. And I guess, you know, when I wrote that article, I was thinking more about.
Becoming a professional software engineer, and I thought that is a sort of a career long field of study, but I think there is lots of things now that people can do where programming is a part of solving what they want to solve without achieving that professional level status. Right. So I am not going to be going and writing a million lines of code, but, you know, I am a biologist or a physicist or something or even a historian. And I have got some data and I want to ask a question of that data.
And I think for that, you do not need 10 years. Right. So there are many shortcuts to being able to answer those kinds of questions. And you see today a lot of emphasis on learning to code, teaching kids how to code. I think that is great, but I wish they would change the message a little bit. Right. So I think code is not the main thing. I do not really care if you know the syntax of JavaScript or if you can connect these blocks together in this visual language.
But what I do care about is that you can analyze a problem. You can think of a solution. You can carry out, you know, make a model, run that model, test the model, see the results, verify that they are reasonable, ask questions and answer them. Right. So it is more modeling and problem solving and you use coding in order to do that. But it is not just learning coding for its own sake.
that is really interesting. So it is actually almost in many cases, it is learning to work with data to extract something useful out of data. So when you say problem solving, you really mean taking some kind of maybe collecting some kind of data set, cleaning it up and saying something interesting about it, which is useful in all kinds of domains.
And, you know, and I see myself being stuck sometimes in kind of the old ways. Right. So, you know, be working on a project, maybe with a younger employee. And we say, oh, well, here is this new package that could help solve this problem and I will go and I will start reading the manuals.
And, you know, I will be two hours into reading the manuals. And then my colleague comes back and says, I am done. Yeah. You know, I downloaded the package. I installed it. I tried calling some things. The first one did not work, the second one on work. Now I am done. And I say, but I have other questions about how does this work and how does that work? And they say, who cares? Right.
I do not need to understand the whole thing. I answered my question. it is a big, complicated package. I do not understand the rest of it, but I got the right answer. And I am just it is hard for me to get into that mindset. I want to understand the whole thing. And, you know, if they wrote a manual, I should probably read it. And but that is not necessarily the right way. I think I have to get used to.
Dealing with more be more comfortable with uncertainty and not knowing everything. Yeah, so I struggle with the same sort of the spectrum between Donald Knuth. Yeah.
who is kind of the very you know, before you can say anything about a problem, he really has to get down to the machine code assembly. Yeah. Versus exactly what you said of of several students in my group that, you know, 20 years old and they can solve almost any problem within a few hours. That would take me probably weeks because I would try to, as you said, read the manual. So.
Do you think the nature of masteries, you are mentioning biology sort of outside disciplines, applying programming, but computer scientists, though, over time there is higher and higher levels of abstraction available now.
So with this week, there is the chance of the summit.
So if you are if you are not particularly into deep learning, but you are still a computer scientist, you can accomplish an incredible amount with tends to flow without really knowing any fundamental internals of machine learning. Do you think the nature of mastery is changing even for computer scientists like what it means to be an expert programmer?
Yeah, I think that is true. You know, we never really should have focused on programmers, right? Because it is still it is the skill and what we really want to focus on is the result. So we built this ecosystem where the way you can get stuff done is by programming it yourself. At least when I started, you know, library functions meant you had square root and that was about it, right? Everything else you built from scratch. And then we built up an ecosystem where a lot of times you can download a lot of stuff that does a big part of what you need.
And so now it is more a question of assembly rather than manufacturing.
And that is a different way of looking at problems from another perspective in terms of mastery and looking at programmers or people that reasonable problems in a computational way. So Google, you know, from the hiring perspective, from the perspective of hiring or building a team of programmers, how do you determine if someone is a good programmer or if somebody again. So I want to deviate. I want to move away from the word programmer, but somebody who could solve problems of large scale data and so on.
what is what is how do you build a team like that that the interviewing process? Yeah, and I and I think as a company grows, you get more expansive in the types of people you are looking for. Right. So I think, you know, in the early days we would interview people. And the question we were trying to ask is, how close are they to Jeff Dean?
And most people, we are pretty far away, but we take the ones that were not that far away.
And so we got kind of a homogeneous group of people who were really great programmers. Then as a company grows, you say, well, we do not want everybody to be the same. They have the same skill set. And so now we are hiring biologists in our health areas and we are hiring physicists and we are hiring mechanical engineers. we are hiring, you know, social scientists and ethnographers and people with different backgrounds who bring different skills.
So you mentioned they you still may partake in code reviews, given that you have a wealth of experience, as Steve also mentioned, that, uh, what areas do you often see and tend to highlight in the code of junior developers of people coming up now, given your background from Lisp to a couple of decades of programming?
Yeah, that is a great question. You know, sometimes I try to look at the flexibility of the design of, yes, you know, this API solve this problem, but where is it going to go in the future? Who else is going to want to call this? And, you know, how are you making it easier for them to do that?
that is a matter of design. it is a documentation. Is it is it sort of an amorphous thing? You can not really put into words. it is just how it feels. If you put yourself in the shoes of a developer, would you use this kind of thing? I think it is how you feel, right. So, yeah, documentation is good, but it is but it is more a design question. If you get the design right, then people will figure it out whether the documentation is good or not and the design is wrong, then it will be hard to use.
How have you yourself changed as a programmer over the years as in a way where you really started to say sort of you want to read the manual, you want to understand the core of the syntax to the how the language is supposed to be used and so on. But what is the evolution been like from the 80s, 90s to today?
I guess one thing is you do not have to worry about the small details of efficiency as much as you used to write. So like I remember, I did my last book in the 90s, and one of the things I wanted to do was say, here is how you do an object system and basically we are going to make it so each object is a hash table and you look up the methods and here is how it works. And then I said, of course, the real.
Common Lisp object system is much more complicated. it is got all these efficiency type issues and this is just a toy. Nobody would do this in real life. And it turns out Python pretty much did exactly what I said. Yeah. And said objects are just dictionaries and yeah, they have a few little tricks as well. But mostly, you know, the thing that would have been 100 times too slow in the 80s is now plenty fast for most everything.
So you had to, as a programmer, let go of perhaps an obsession that I remember coming up with of trying to write efficient code.
Yeah, that to say what really matters is the total time it takes to get the project done. And most of that is going to be the programmer time. Yeah. So if you are a little bit less efficient but it makes it easier to understand and modify, then that is the right tradeoff. So you have written quite a bit about Lisp. you have become programmings unless you have a lot of code out there. that is unless so myself and people who do not know Elizabeth should look it up.
it is my favorite language for many. Research is it is a favorite language, the favorite language they never use these days. So what part of the list do you find most beautiful and powerful?
So I think the beautiful part is the simplicity that in half a page you can define the whole language. And other languages do not have that, so you feel like you can hold everything in your head. Then, you know, a lot of people say, well, then that is too simple, you know, here is all these things I want to do and, you know, my Java or Python or whatever has 100 or 200 or 300 different syntax rules. And do not I need all those and lists?
The answer was no. we are only going to give you eight or so syntax rules, but we are going to allow you to define your own. And so that was a very powerful idea. And I think this idea of saying I can start with my problem and with my data and then I can build the language I want for that problem and for that data, and then I can make Lisp define that language. So you you are sort of mixing levels and saying, I am simultaneously a programmer in a language and a language designer.
And that allows a better match between your problem and your eventual code. And I think Liz had done that better than other languages.
Yes, very elegant implementation of functional programming. But why do you think this has not had the mass adoption and success of languages like Python? Is it the parentheses? Is it all the parentheses? Yeah.
So I think a couple of things. So one was I think it was designed for a single programmer or a small team. And skilled programmer who had the good taste to say, well, I am I am doing language design and I have to make good choices and we make good choices. that is great. If you make bad choices, you can hurt yourself and it can be hard for other people on the team to understand it. So I think there was a limit to the scale of the size of a project in terms of number of people that list was good for.
And as an industry, we kind of grew beyond that. I think it is in part the parentheses. You know, one of the jokes is the acronym for LISP is lots of irritating, silly parentheses. My acronym was Lisp is syntactically pure. Saying all you need is parentheses and atoms, but I remember, you know, we had the the textbook and because we did it in the 90s, we had we had pseudocode in the book. But then we said, well, we will have lisp on.
Like, that is the language of A.I. at the time. And I remember some of the students complaining because they had not had lisp before and they did not quite understand what was going on. And I remember one student complained, I do not understand how this pseudocode corresponds to this lisp. And there was a one to one correspondence between the the symbols in the code and the pseudocode. And the only thing difference was the parentheses. So I said it must be that for some people, a certain number of left parentheses shuts off their brain.
Yeah, it is very it is very possible in that sense in Python just goes the other way. And so so that was the point at which I said, OK, can not have only lisp. that is a language because I, you know, I do not want to you know, you only got 10 or 12 or 15 weeks or whatever it is to teach. And I do not want to waste two weeks of that teaching lisp. So I say I got to have another language.
Java was the most popular language at the time I started doing that. And then I said it is really hard to have a one to one correspondence between the pseudocode and the Java because Java so verbose. So then I said, I am going to do a survey and find the language that is most like my pseudocode and turn out Python basically was my pseudocode.
Somehow I had channeled Guido designed a pseudocode that was the same as Python, although I had not heard of Python at that point. And from then on, that is what I have been using because it is been a good match.
So what is the story in Python behind by Études? Your GitHub repository with puzzles and exercises in Python is pretty fun. Yeah, just it seems like fun. Uh, you know, I like doing puzzles and I like being an educator. I did a class with Udacity 212, I think it was that was basically problem solving using Python and looking at different problems that is try to feed that class. In terms of the exercise, I was wondering what that. Yeah.
So the class the class came first. Yeah. Some of the stuff that is ineptitudes was write ups of what was in the class and then some of it was just continuing to to work on new problems.
So what is the organizing madness of Pi tuj. This is just a collection of cool exercise, just whatever I thought was fun. OK, awesome. So you were the director of Search Quality at Google from 2001 to 2005 and the early days when there is just a few employees and when the company was growing like crazy. Right.
So I mean, Google revolutionized the way we discover, share and aggregate knowledge. So just this is, uh, this is one of the fundamental aspects of civilization, is information being shared. And there is different mechanism throughout history. But Google is just 10x improve that. Right. And you are part of that. Right. People discovering that information. So what were some of the challenges and the philosophical or the technical level in those early days? It definitely was an exciting time and as you say, we were doubling in size every year.
And the challenges were we wanted to get the right answers right and we had to figure out what that meant, we had to implement that and we had to make it all efficient and. We had to keep on testing and seeing if we were delivering good answers and now when you say good answers, that means whatever people are typing in in terms of keywords and terms, that kind of thing, that the that the results to get are ordered by the desirability for them of those results.
Like they are like the first thing they click on will likely be the thing that they were actually looking for. Right. One of the metrics we had was focused on the first thing. Some of it was focused on the whole page. Some of it was focused on, you know, the top three or so. So we looked at a lot of different metrics for for how well we were doing and we broke it down into subclasses of, you know, maybe here is a type of of query that we are not doing well on and we try to fix that.
Early on, we started to realize that we were in an adversarial position. Right. So we started thinking what we are kind of like the card catalogue in the library. Right? The books are here and we are off to the side and we are just reflecting what is there. And then we realized every time we make a change, the webmasters make a change and it is game theoretic. And so we had to think not only is this the right move for us to make now, but also if we make this move, what is the countermove going to be?
Is that going to get us into a work worse place, in which case we will not make that move, will make it OK.
And did you find I mean, I assume with the popularity and the growth of the Internet that people were creating new content. So you are almost helping guide the creation?
Yeah. So that is certainly true, right. So we we we definitely changed the structure of the network. Right. So if you think back, you know, in the very early days, Larry and Sergei had the page rank paper and Jon Kleinberg had this hub's in authorities model, which says The Web is made out of these hubs, which will be my page of Google links about dogs or whatever, and people would just list links and then there would be authorities, which were the ones the page about dogs that most people link to.
That does not happen anymore, people do not bother to say my page of Google links because we took over that function, right? So so we changed the way that worked.
Did you imagine back then that the Internet would be as massively vibrant as it is today? I mean, it was already growing quickly, but it is just another I do not know if you have ever seen it today.
If you sit back and you just look at the Internet with wonder the amount of content that is just constantly being created, constantly being shared, unemployed.
Yeah, it is it is always been surprising to me. I guess I am not very good at predicting the future in the future. And I remember, you know, being a graduate student in 1980 or so and, you know, we had the ARPANET.
And then there was this proposal to commercialize it and have this Internet and this crazy, Senator Gore thought that might be a good idea. And I remember thinking, oh, come on, you can not you can not expect commercial company to understand this technology. they will never be able to do it. Yeah, OK. We can have this dot com domain, but it will not go anywhere. So I was wrong. Al Gore was right. At the same time, the nature of what it means to be a commercial company has changed to.
So Google is at its founding is different than a you know, what companies were before, I think. Right.
So there is all these business models that are so different than what was possible back then.
So in terms of predicting the future, what do you think it takes to build a system that approaches human level intelligence?
you have talked about, of course, that, you know, we should not be so obsessed about creating human level intelligence. We just create systems that are very useful for humans. But what do you think it takes you to approach that level? Right. So certainly I do not think human level intelligence is one thing. Right. So I think there is lots of different tasks, lots of different capabilities. I also do not think that should be the goal, right? So, you know, I would not want to create a calculator that could do multiplication at human level.
Right. But that would be a step backwards. And so for many things, we should be aiming far beyond human level for other things. Maybe human level is a good level to aim at. And for others, we say, well, let us not bother doing this because we are we already have humans can take on those tasks. So, as you say, I like to focus on what is a useful tool and and in some cases, being a human level is an important part of crossing that threshold to make the tool useful.
So we see in things like these personal assistants now that you get either on your phone or on a speaker that sits on the table, you want to be able to have a conversation with those. And and I think as an industry, we have not quite figured out what the right model is for what these things can do. And we are aiming towards what you just have a conversation with them the way you can with a person. Right. But we have not delivered on that model yet.
Right. So you can ask it. what is the weather? You can ask it, play some nice songs and, you know, five or six other things. And then you run out of stuff that it can do in terms of a deep, meaningful connection. So you have mentioned the movie her as one of your favorite movies. Do you think it is possible for a human being to fall in love with an AI system assistant, as you mentioned, taking this big leap from what is the weather to, you know, having a deep connection?
Yeah, I think as people, that is what we love to do. And I was at a showing of her where we had a panel discussion and somebody asked me, what other movie do you think her is similar to? And my answer was Life of Brian, which which is not a science fiction movie. But both movies are about wanting to believe in something that is not necessarily real.
Yeah. By the way, for people that I know, it is Monty Python. Yeah. Yeah, it is been brilliantly put. Right. So.
So, I mean, I think that is just the way we are. We want to trust. We want to believe. We want to fall in love. And it does not necessarily take that much. Right. So, you know, my kids fell in love with their teddy bear and the teddy bear was not very interactive. Right. So that is all us pushing our feelings onto our devices and our things. And I think that that is what we like to do.
So we will continue to do that.
So, yeah, as human beings will long for that connection. And just I have to do a little bit of work to to catch up in the other end. Yeah. And certainly, you know, if you can get to dog level, a lot of people have invested a lot of love in their pets, in their pets. Some some people, as I have been told in working with autonomous vehicles, have invested a lot of love into their inanimate cars.
So it really does not take much.
So what is a good test? To linger on a topic that may be silly or a little bit philosophical, what is a good test of intelligence, in your view? Is national conversation like in the Turing test, a good a good test? Put another way, what would impress you if you saw a computer do it these days?
Oh, I mean, I get past all of that. Right. Really impressive. You know, go playing Starcraft playing. Those are all pretty cool. You know, and I think short conversation is important, I think, you know, we sometimes have these tests where it is easy to fool the system, where you can have a chat bot that can have a conversation, but you never it never gets into a situation where it has to be deep enough that it really reveals itself as being intelligent or not.
I think, you know, Turing suggested that. But I think if he were alive, he would say, you know, I did not really mean that seriously. Right. And I think, you know, this is just my opinion. But I think Turing's point was not that this test of conversation is a good test. I think his point was having a test is the right thing. So rather than having the philosophers say, oh, no, A.I. is impossible, you should say, well, we will just have a test.
And then the result of that will tell us the answer. And it does not necessarily have to be a conversation test. that is right.
And coming up, a new better test as the technology evolves is probably the right way.
Do you worry, as a lot of the general public does about not a lot, but some vocal part of the general public about the existential threat of artificial intelligence? So looking farther into the future, as you said, most of us are now able to predict much so when shrouded in such mystery, there is a concern of, well, you think it is starting about worst case? Is that something that occupies your mind space? Much so.
I certainly think about threats. I think about dangers. And I think any new technology has positives and negatives. And if it is a powerful technology, it can be used for bad as well as for good. So I am certainly not worried about the robot apocalypse and the Terminator type scenarios. I am worried about. Change in employment and are we going to be able to react fast enough to deal with that? I think we are you know, we are already seeing it today where a lot of people are disgruntled about the way income inequality is working and and automation could help accelerate those kinds of problems.
I see powerful technologies can always be used as weapons, whether they are robots or drones or whatever. Some of that we are seeing and do a lot of it. You do not need a guy. And I do not know what is what is a worse threat if it is a autonomous drone or it is CRISPR technology becoming available or we have lots of threats to face and some of them involved and some of them do not.
So the threats that technology presents are you, for the most part, optimistic about technology, also alleviating those threats or creating new opportunities or protecting us from the more detrimental effects of these?
I do not know it again, it is hard to predict the future. And yes, as a society so far, we have survived nuclear bombs and other things. Of course, only societies that have survived are having this conversation. So maybe that is survivorship bias. Yeah. What problem stands out to you as exciting, challenging, impactful to work on in the near future for yourself, for the community and broadly? So, you know, we talked about these assistants in conversation.
I think that is a great area. I think combining. Common sense reasoning with the power of data is a great area. In which application and in conversation was just broadly, just in general, yeah, as a programmer, I am interested in programming tools, both in terms of, you know, the current systems we have today with denser flow and so on. Can we make them much easier to use for a broader class of people? And also, can we apply machine learning to the more traditional type of programming?
So, you know, when you go to Google and you type in a query and you spell something wrong, it says, did you mean? And the reason we are able to do that is because lots of other people made a similar error and then they corrected it. We should be able to go into our code bases and our bug fix bases. And when I type a line of code, it should be able to say, did you mean such and such?
If you type this today, you are probably going to type in this bug fix tomorrow. Yeah, that is a really exciting application of almost an assistant for the coding programming experience at every level.
So I think I can safely speak for the entire A.I. community.
First of all, thank you for the amazing work you have done, certainly for the amazing work you have done with AI, a modern approach book. And I think we are all looking forward very much for the fourth edition and then the fifth edition and so on. So, Peter, thank you so much for talking today. Yeah, thank you. Pleasure.
